<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- seo --><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>A Quick Look at DF I/O (basic ETL w/JSON over http to CSV and Parquet on MinIO) | Scaling Python ML</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="A Quick Look at DF I/O (basic ETL w/JSON over http to CSV and Parquet on MinIO)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Now that we&#8217;ve got Dask installed, it&#8217;s time to try some simple data preparation and extract, transform, load(ETL). While ETL is often not the most exciting thing, getting data is the first step of most adventures. Data tools don&#8217;t exist in a vacuum; the data normally comes from somewhere else, and the data or models we make need to be useable with other tools. Because of this, the formats and systems that a tool can interact with can make a difference between it being a fit or needing to keep looking. To simplify your life with I/O, you should make sure your notebook (or client) runs inside the same cluster as the workers." />
<meta property="og:description" content="Now that we&#8217;ve got Dask installed, it&#8217;s time to try some simple data preparation and extract, transform, load(ETL). While ETL is often not the most exciting thing, getting data is the first step of most adventures. Data tools don&#8217;t exist in a vacuum; the data normally comes from somewhere else, and the data or models we make need to be useable with other tools. Because of this, the formats and systems that a tool can interact with can make a difference between it being a fit or needing to keep looking. To simplify your life with I/O, you should make sure your notebook (or client) runs inside the same cluster as the workers." />
<link rel="canonical" href="https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html" />
<meta property="og:url" content="https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html" />
<meta property="og:site_name" content="Scaling Python ML" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-29T00:00:00-07:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"A Quick Look at DF I/O (basic ETL w/JSON over http to CSV and Parquet on MinIO)","dateModified":"2021-06-29T00:00:00-07:00","datePublished":"2021-06-29T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html"},"url":"https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html","description":"Now that we&#8217;ve got Dask installed, it&#8217;s time to try some simple data preparation and extract, transform, load(ETL). While ETL is often not the most exciting thing, getting data is the first step of most adventures. Data tools don&#8217;t exist in a vacuum; the data normally comes from somewhere else, and the data or models we make need to be useable with other tools. Because of this, the formats and systems that a tool can interact with can make a difference between it being a fit or needing to keep looking. To simplify your life with I/O, you should make sure your notebook (or client) runs inside the same cluster as the workers.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<!-- end seo -->
  <link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://scalingpythonml.com/feed.xml" title="Scaling Python ML" /><!-- Analytics --><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-175499613-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<!-- End analytics -->

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
          ]}
        );
      });
    </script>
  

  <script>
  function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
  }
  window.onload = wrap_img;
  </script>

  <!-- favicon -->
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <!-- End favicon -->

</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Scaling Python ML</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about.html">About</a><a class="page-link" href="/mailinglist.html">Mailinglist</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A Quick Look at DF I/O (basic ETL w/JSON over http to CSV and Parquet on MinIO)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2021-06-29T00:00:00-07:00" itemprop="datePublished">Jun 29, 2021
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Now that we&#8217;ve got Dask installed, it&#8217;s time to try some simple data preparation and extract, transform, load(ETL). While ETL is often not the most exciting thing, getting data is the first step of most adventures. Data tools don&#8217;t exist in a vacuum; the data normally comes from somewhere else, and the data or models we make need to be useable with other tools. Because of this, the formats and systems that a tool can interact with can make a difference between it being a fit or needing to keep looking. To simplify your life with I/O, you should make sure your notebook (or client) runs inside the same cluster as the workers.</p>
</div>
<div class="paragraph">
<p>For now, we&#8217;ll start by taking all of the GitHub activity <a href="https://www.gharchive.org/">from gharchive</a> and re-partitioning it in a way that will allow us to try and train models on a per-organization and per-repo basis.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_file-systems-e-g-data-stores-sinks-and-well-file-systems">File Systems (e.g., Data Stores, Sinks, and well File Systems)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Often, the need to scale our Python programs comes at least in part from larger input sizes. When we use distributed systems (like Kubernetes), the data must be accessible to all workers. For this reason, we end up needing to get our data over the network. This does not have to be what one would traditionally think of as a network file system (like, say, NFS or AFS); it can include things such as HTTP, S3, HDFS, etc. All of these protocols expose some common file-like access.</p>
</div>
<div class="paragraph">
<p>Dask&#8217;s file access layer uses <a href="https://github.com/intake/filesystem_spec">FSSPEC</a>, from the <a href="https://intake.readthedocs.io/en/latest/">intake project</a>, to access the different file systems. Since FSSPEC supports such a range of file systems, it does not install the requirements for every supported file system. You can see what file systems are supported, and which ones need additional packages by running:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">fsspec.registry</span> <span style="color: #008000; font-weight: bold">import</span> known_implementations
known_implementations</code></pre>
</div>
</div>
<div class="paragraph">
<p>In my case the known implementations returns:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code><span></span>{&#39;file&#39;: {&#39;class&#39;: &#39;fsspec.implementations.local.LocalFileSystem&#39;},
 &#39;memory&#39;: {&#39;class&#39;: &#39;fsspec.implementations.memory.MemoryFileSystem&#39;},
 &#39;dropbox&#39;: {&#39;class&#39;: &#39;dropboxdrivefs.DropboxDriveFileSystem&#39;,
  &#39;err&#39;: &#39;DropboxFileSystem requires &quot;dropboxdrivefs&quot;,&quot;requests&quot; and &quot;dropbox&quot; to be installed&#39;},
 &#39;http&#39;: {&#39;class&#39;: &#39;fsspec.implementations.http.HTTPFileSystem&#39;,
  &#39;err&#39;: &#39;HTTPFileSystem requires &quot;requests&quot; and &quot;aiohttp&quot; to be installed&#39;},
 &#39;https&#39;: {&#39;class&#39;: &#39;fsspec.implementations.http.HTTPFileSystem&#39;,
  &#39;err&#39;: &#39;HTTPFileSystem requires &quot;requests&quot; and &quot;aiohttp&quot; to be installed&#39;},
 &#39;zip&#39;: {&#39;class&#39;: &#39;fsspec.implementations.zip.ZipFileSystem&#39;},
 &#39;gcs&#39;: {&#39;class&#39;: &#39;gcsfs.GCSFileSystem&#39;,
  &#39;err&#39;: &#39;Please install gcsfs to access Google Storage&#39;},
 &#39;gs&#39;: {&#39;class&#39;: &#39;gcsfs.GCSFileSystem&#39;,
  &#39;err&#39;: &#39;Please install gcsfs to access Google Storage&#39;},
 &#39;gdrive&#39;: {&#39;class&#39;: &#39;gdrivefs.GoogleDriveFileSystem&#39;,
  &#39;err&#39;: &#39;Please install gdrivefs for access to Google Drive&#39;},
 &#39;sftp&#39;: {&#39;class&#39;: &#39;fsspec.implementations.sftp.SFTPFileSystem&#39;,
  &#39;err&#39;: &#39;SFTPFileSystem requires &quot;paramiko&quot; to be installed&#39;},
 &#39;ssh&#39;: {&#39;class&#39;: &#39;fsspec.implementations.sftp.SFTPFileSystem&#39;,
  &#39;err&#39;: &#39;SFTPFileSystem requires &quot;paramiko&quot; to be installed&#39;},
 &#39;ftp&#39;: {&#39;class&#39;: &#39;fsspec.implementations.ftp.FTPFileSystem&#39;},
 &#39;hdfs&#39;: {&#39;class&#39;: &#39;fsspec.implementations.hdfs.PyArrowHDFS&#39;,
  &#39;err&#39;: &#39;pyarrow and local java libraries required for HDFS&#39;},
 &#39;webhdfs&#39;: {&#39;class&#39;: &#39;fsspec.implementations.webhdfs.WebHDFS&#39;,
  &#39;err&#39;: &#39;webHDFS access requires &quot;requests&quot; to be installed&#39;},
 &#39;s3&#39;: {&#39;class&#39;: &#39;s3fs.S3FileSystem&#39;, &#39;err&#39;: &#39;Install s3fs to access S3&#39;},
 &#39;adl&#39;: {&#39;class&#39;: &#39;adlfs.AzureDatalakeFileSystem&#39;,
  &#39;err&#39;: &#39;Install adlfs to access Azure Datalake Gen1&#39;},
 &#39;abfs&#39;: {&#39;class&#39;: &#39;adlfs.AzureBlobFileSystem&#39;,
  &#39;err&#39;: &#39;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&#39;},
 &#39;az&#39;: {&#39;class&#39;: &#39;adlfs.AzureBlobFileSystem&#39;,
  &#39;err&#39;: &#39;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&#39;},
 &#39;cached&#39;: {&#39;class&#39;: &#39;fsspec.implementations.cached.CachingFileSystem&#39;},
 &#39;blockcache&#39;: {&#39;class&#39;: &#39;fsspec.implementations.cached.CachingFileSystem&#39;},
 &#39;filecache&#39;: {&#39;class&#39;: &#39;fsspec.implementations.cached.WholeFileCacheFileSystem&#39;},
 &#39;simplecache&#39;: {&#39;class&#39;: &#39;fsspec.implementations.cached.SimpleCacheFileSystem&#39;},
 &#39;dask&#39;: {&#39;class&#39;: &#39;fsspec.implementations.dask.DaskWorkerFileSystem&#39;,
  &#39;err&#39;: &#39;Install dask distributed to access worker file system&#39;},
 &#39;github&#39;: {&#39;class&#39;: &#39;fsspec.implementations.github.GithubFileSystem&#39;,
  &#39;err&#39;: &#39;Install the requests package to use the github FS&#39;},
 &#39;git&#39;: {&#39;class&#39;: &#39;fsspec.implementations.git.GitFileSystem&#39;,
  &#39;err&#39;: &#39;Install pygit2 to browse local git repos&#39;},
 &#39;smb&#39;: {&#39;class&#39;: &#39;fsspec.implementations.smb.SMBFileSystem&#39;,
  &#39;err&#39;: &#39;SMB requires &quot;smbprotocol&quot; or &quot;smbprotocol[kerberos]&quot; installed&#39;},
 &#39;jupyter&#39;: {&#39;class&#39;: &#39;fsspec.implementations.jupyter.JupyterFileSystem&#39;,
  &#39;err&#39;: &#39;Jupyter FS requires requests to be installed&#39;},
 &#39;jlab&#39;: {&#39;class&#39;: &#39;fsspec.implementations.jupyter.JupyterFileSystem&#39;,
  &#39;err&#39;: &#39;Jupyter FS requires requests to be installed&#39;}}</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you don&#8217;t see your file system supported, there are a few options ranging from writing a new spec for FSSPEC, to using a FUSE filesystem layer, or copying the data to a support file system.</p>
</div>
<div class="paragraph">
<p>Since I&#8217;m focused on experimentation, I decided to install all of the extra packages from <a href="https://github.com/intake/filesystem_spec/blob/master/setup.py">https://github.com/intake/filesystem_spec/blob/master/setup.py</a> as part of my Dockerfile in <a href="#ex_install_all_fs">[ex_install_all_fs]</a>. If we just wanted to support our example (reading from http and writing to S3 compatible FS) we could simplify that to <a href="#ex_install_just_s3_http">[ex_install_just_s3_http]</a>.</p>
</div>
<div id="ex_install_just_s3_http" class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="bash"><span></span>pip install fsspec<span style="color: #666666">[</span>s3<span style="color: #666666">]</span> aiohttp</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Often distributed file systems require some level of configuration, although sometimes this configuration is "hidden" from the end user so it is not always as visible. With Dask, the configuration needs to be specified along with each reading/writing operation which makes the configuration more visible.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>In Hadoop based systems, configuration is often read from a combination of environment variables and mystery XML files, which, when working can feel like magic&#8201;&#8212;&#8201;but keep in mind, the most difficult configuration to debug is the configuration you can not find.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Since we&#8217;re pulling our data over public http, we don&#8217;t need special configuration for that. However, for our write side, I&#8217;m using minio (an S3-compatible file system) which needs configuration. The endpoint_url is the service name from <code>helm ls -n minio</code> plus [namespace].svc.cluster.local. The key and secret are specified during the install (which we did in the previous post).</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span>minio_storage_options <span style="color: #666666">=</span> {
    <span style="color: #BA2121">&quot;key&quot;</span>: <span style="color: #BA2121">&quot;YOURACCESSKEY&quot;</span>,
    <span style="color: #BA2121">&quot;secret&quot;</span>: <span style="color: #BA2121">&quot;YOURSECRETKEY&quot;</span>,
    <span style="color: #BA2121">&quot;client_kwargs&quot;</span>: {
        <span style="color: #BA2121">&quot;endpoint_url&quot;</span>: <span style="color: #BA2121">&quot;http://minio-1602984784.minio.svc.cluster.local:9000&quot;</span>,
        <span style="color: #BA2121">&quot;region_name&quot;</span>: <span style="color: #BA2121">&#39;us-east-1&#39;</span>
    },
    <span style="color: #BA2121">&quot;config_kwargs&quot;</span>: {<span style="color: #BA2121">&quot;s3&quot;</span>: {<span style="color: #BA2121">&quot;signature_version&quot;</span>: <span style="color: #BA2121">&#39;s3v4&#39;</span>}},
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>We&#8217;ll use these storage options in the next section when writing data to our MinIO server.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
<div class="paragraph">
<p>The first time I did this, I was unable to figure out what was going on for a few hours because I had "anon": "false", and the false string was automatically converted to the true boolean value.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Sometimes data can also come from or be written to things that are even less like file systems than the web, such as databases. In Dask, these are represented in a way closer to how file formats are represented, which is what we are going to explore next.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_file-formats">(File) Formats</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Dask has built in support for a variety of formats on top of the different file systems. Both the Bag and DataFrame APIs have their own IO functions (<a href="https://docs.dask.org/en/latest/bag-creation.html">bag IO</a> &amp; <a href="https://docs.dask.org/en/latest/dataframe-api.html#create-dataframes">dataframe IO</a>).</p>
</div>
<div class="paragraph">
<p>In our case, the input format we&#8217;ve got is JSON and the target output format is Parquet. Dask DataFrame&#8217;s IO library supports both of those formats so we&#8217;ll use the DataFrame API. We could also do this with the Bag API.</p>
</div>
<div class="sect2">
<h3 id="_reading">Reading</h3>
<div class="paragraph">
<p>To load the data we need to specify the files we want to load. On file systems that support listing (like S3, HDFS, local, etc.), we can use wild cards, but when using a file system without listing support we need to create a list of all of the files.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span>gh_archive_files<span style="color: #666666">=</span>[]
<span style="color: #008000; font-weight: bold">while</span> current_date <span style="color: #666666">&lt;</span> datetime<span style="color: #666666">.</span>datetime<span style="color: #666666">.</span>now() <span style="color: #666666">-</span>  datetime<span style="color: #666666">.</span>timedelta(days<span style="color: #666666">=1</span>):
    current_date <span style="color: #666666">=</span> current_date <span style="color: #666666">+</span> datetime<span style="color: #666666">.</span>timedelta(hours<span style="color: #666666">=1</span>)
    datestring <span style="color: #666666">=</span> f<span style="color: #BA2121">&#39;{current_date.year}-{current_date.month:02}-{current_date.day:02}-{current_date.hour}&#39;</span>
    gh_url <span style="color: #666666">=</span> f<span style="color: #BA2121">&#39;http://data.githubarchive.org/{datestring}.json.gz&#39;</span>
    gh_archive_files<span style="color: #666666">.</span>append(gh_url)</code></pre>
</div>
</div>
<div class="paragraph">
<p>When I have a number of different inputs, I like to start with loading just the first file to explore the schema.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span>df <span style="color: #666666">=</span> dd<span style="color: #666666">.</span>read_json(gh_archive_files, compression<span style="color: #666666">=</span><span style="color: #BA2121">&#39;gzip&#39;</span>)
df<span style="color: #666666">.</span>columns</code></pre>
</div>
</div>
<div class="paragraph">
<p>After loading our initial input, calling "head" on the distributed DataFrame lets us see what&#8217;s going on.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span>df<span style="color: #666666">.</span>head()</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note the result of doing this (in IPython/Jupyter) is displayed using the normal pandas display logic, resulting in a nice image <a href="#dfheadimg">[dfheadimg]</a>.</p>
</div>
<div id="dfheadimg" class="imageblock">
<div class="content">
<img src="/images/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio-df-head.png" alt="Image of Dataframe display in the notebook">
</div>
</div>
<div class="paragraph">
<p>If you&#8217;ve called <code>df.head</code> in Spark, you&#8217;ll note this is a much nicer default view. That being said the data needs a bit of cleaning up.</p>
</div>
</div>
<div class="sect2">
<h3 id="_some-quick-tidying-up">Some Quick Tidying Up</h3>
<div class="paragraph">
<p>As we can see, there is nested JSON data in the DataFrame. I would like to partition on the project name so that, later, we can play around with data per-project without having to load everything (although I don&#8217;t think there is any automated filter push down). However, we can&#8217;t partition using a column that is a nested data structure, so we need to extract the project name.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">clean_record</span>(record):
    r <span style="color: #666666">=</span> {
        <span style="color: #BA2121">&quot;repo&quot;</span>: record[cols<span style="color: #666666">.</span>get_loc(<span style="color: #BA2121">&quot;repo&quot;</span>)],
        <span style="color: #BA2121">&quot;repo_name&quot;</span>: record[cols<span style="color: #666666">.</span>get_loc(<span style="color: #BA2121">&quot;repo&quot;</span>)][<span style="color: #BA2121">&quot;name&quot;</span>],
        <span style="color: #BA2121">&quot;type&quot;</span>: record[cols<span style="color: #666666">.</span>get_loc(<span style="color: #BA2121">&quot;type&quot;</span>)],
        <span style="color: #BA2121">&quot;id&quot;</span>: record[cols<span style="color: #666666">.</span>get_loc(<span style="color: #BA2121">&quot;id&quot;</span>)],
        <span style="color: #BA2121">&quot;created_at&quot;</span>: record[cols<span style="color: #666666">.</span>get_loc(<span style="color: #BA2121">&quot;created_at&quot;</span>)],
        <span style="color: #BA2121">&quot;payload&quot;</span>: record[cols<span style="color: #666666">.</span>get_loc(<span style="color: #BA2121">&quot;payload&quot;</span>)]}
    <span style="color: #008000; font-weight: bold">return</span> r

cleaned_up_bag <span style="color: #666666">=</span> data_bag<span style="color: #666666">.</span>map(clean_record)
res <span style="color: #666666">=</span> cleaned_up_bag<span style="color: #666666">.</span>to_dataframe()</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_writes">Writes</h3>
<div class="paragraph">
<p>The write side looks very similar to the read side, but we&#8217;re going to use the minio_storage_options object we created earlier.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight" style="background: #f8f8f8;"><code data-lang="python"><span></span>res<span style="color: #666666">.</span>to_parquet(<span style="color: #BA2121">&quot;s3://dask-test/boop-test-partioned&quot;</span>,
              partition_on<span style="color: #666666">=</span>[<span style="color: #BA2121">&quot;type&quot;</span>, <span style="color: #BA2121">&quot;repo_name&quot;</span>], <span style="color: #408080; font-style: italic"># Based on &quot; there will be no global groupby.&quot; I think this is the value we want.</span>
              compression<span style="color: #666666">=</span><span style="color: #BA2121">&quot;gzip&quot;</span>,
              storage_options<span style="color: #666666">=</span>minio_storage_options, engine<span style="color: #666666">=</span><span style="color: #BA2121">&quot;pyarrow&quot;</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Not all of  the Dask formats support partitioned writes. When a format does not support partition_on or other partioned writes, Dask will need to either all of the data back to either a single executor or the client Python process. This can cause failures with large datasets.</p>
</div>
</div>
<div class="sect2">
<h3 id="_compression">Compression</h3>
<div class="paragraph">
<p>Data is often stored in compressed formats, and the same library used to abstract file system access in Dask also abstracts compression. Some compression algorithms support random reads, but many do not. For people coming from the Hadoop ecosystem this can be thought of as the impact on "splitable."</p>
</div>
<div class="paragraph">
<p>Just because the underlying compression algorithm may support random reads does not mean that the FSSPEC wrapper will. Unfortunately, there is no current, easy way to check what a compression format supports besides testing it out or reading the source code.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
<div class="paragraph">
<p>Dask does not support "streaming" non-random access input formats. This means that the data inside a file must be able to fit entirely in memory.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conclusion">Conclusion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Dask I/O integrates pretty well into much of the existing "big data" ecosystem, although the methods of specifying configuration are a little bit different. Some nested data structures can be difficult to represent in certain formats with Dask, although as the Python libraries for these formats continue to improve so will Dask&#8217;s support.</p>
</div>
</div>
</div>
  </div><a class="u-url" href="/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Scaling Python ML</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Scaling Python ML</li><li><a class="u-email" href="mailto:holden@pigscanfly.ca">holden@pigscanfly.ca</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/scalingpythonml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">scalingpythonml</span></a></li><li><a href="https://www.twitter.com/holdenkarau"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">holdenkarau</span></a></li><li><a href="https://youtube.com/holdenkarau"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">holdenkarau</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Blog of my adventures working with different tools for scaling Python ML workloads.</p>
      </div>
    </div>

    <br />

    If you enjoy this work and have some extra $s, consider sponsoring <a href="https://github.com/sponsors/holdenk">my OSS work</a>.

    <!-- Disclamer -->

    This blog does not represent any of my employers, software projects, or foundations I'm a part of.
    I am one of the developers of Apache Spark <a href="https://amzn.to/2O6KYYH">and have some books published on the topic</a> <a href="https://amzn.to/2IA6Yf0">(plus a new Kubeflow book)</a> that may influence my views.
    Some of the links on this blog may generate an affiliate commission. I also earn royalties from my books.
    Generally speaking these do not cover the amount I spend on these adventures, but help defray my hardware, <a href="https://amzn.to/31mIOeK">coffee</a>, and <a href="https://dynamodonut.com/">artisinal doughnut</a> costs.

<!-- License -->
    <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />The posts on this blog are licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>. <br />

<!-- Fork me on github -->
<a href="https://github.com/scalingpythonml/scalingpythonml.github.io" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

  </div>

</footer>
</body>

</html>
