<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://scalingpythonml.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://scalingpythonml.com/" rel="alternate" type="text/html" /><updated>2021-06-29T22:28:59-07:00</updated><id>https://scalingpythonml.com/feed.xml</id><title type="html">Scaling Python ML</title><subtitle>Blog of my adventures working with different tools for scaling Python ML workloads.</subtitle><entry><title type="html">A Quick Look at DF I/O (basic ETL w/JSON over http to CSV and Parquet on MinIO)</title><link href="https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html" rel="alternate" type="text/html" title="A Quick Look at DF I/O (basic ETL w/JSON over http to CSV and Parquet on MinIO)" /><published>2021-06-29T00:00:00-07:00</published><updated>2021-06-29T00:00:00-07:00</updated><id>https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio</id><content type="html" xml:base="https://scalingpythonml.com/2021/06/29/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that we&amp;#8217;ve got Dask installed, it&amp;#8217;s time to try some simple data preparation and extract, transform, load(ETL). While ETL is often not the most exciting thing, getting data is the first step of most adventures. Data tools don&amp;#8217;t exist in a vacuum; the data normally comes from somewhere else, and the data or models we make need to be useable with other tools. Because of this, the formats and systems that a tool can interact with can make a difference between it being a fit or needing to keep looking. To simplify your life with I/O, you should make sure your notebook (or client) runs inside the same cluster as the workers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For now, we&amp;#8217;ll start by taking all of the GitHub activity &lt;a href=&quot;https://www.gharchive.org/&quot;&gt;from gharchive&lt;/a&gt; and re-partitioning it in a way that will allow us to try and train models on a per-organization and per-repo basis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_file-systems-e-g-data-stores-sinks-and-well-file-systems&quot;&gt;File Systems (e.g., Data Stores, Sinks, and well File Systems)&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Often, the need to scale our Python programs comes at least in part from larger input sizes. When we use distributed systems (like Kubernetes), the data must be accessible to all workers. For this reason, we end up needing to get our data over the network. This does not have to be what one would traditionally think of as a network file system (like, say, NFS or AFS); it can include things such as HTTP, S3, HDFS, etc. All of these protocols expose some common file-like access.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dask&amp;#8217;s file access layer uses &lt;a href=&quot;https://github.com/intake/filesystem_spec&quot;&gt;FSSPEC&lt;/a&gt;, from the &lt;a href=&quot;https://intake.readthedocs.io/en/latest/&quot;&gt;intake project&lt;/a&gt;, to access the different file systems. Since FSSPEC supports such a range of file systems, it does not install the requirements for every supported file system. You can see what file systems are supported, and which ones need additional packages by running:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;from&lt;/span&gt; &lt;span style=&quot;color: #0000FF; font-weight: bold&quot;&gt;fsspec.registry&lt;/span&gt; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;import&lt;/span&gt; known_implementations
known_implementations&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In my case the known implementations returns:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;/span&gt;{&amp;#39;file&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.local.LocalFileSystem&amp;#39;},
 &amp;#39;memory&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.memory.MemoryFileSystem&amp;#39;},
 &amp;#39;dropbox&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;dropboxdrivefs.DropboxDriveFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;DropboxFileSystem requires &amp;quot;dropboxdrivefs&amp;quot;,&amp;quot;requests&amp;quot; and &amp;quot;dropbox&amp;quot; to be installed&amp;#39;},
 &amp;#39;http&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.http.HTTPFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;HTTPFileSystem requires &amp;quot;requests&amp;quot; and &amp;quot;aiohttp&amp;quot; to be installed&amp;#39;},
 &amp;#39;https&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.http.HTTPFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;HTTPFileSystem requires &amp;quot;requests&amp;quot; and &amp;quot;aiohttp&amp;quot; to be installed&amp;#39;},
 &amp;#39;zip&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.zip.ZipFileSystem&amp;#39;},
 &amp;#39;gcs&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;gcsfs.GCSFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Please install gcsfs to access Google Storage&amp;#39;},
 &amp;#39;gs&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;gcsfs.GCSFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Please install gcsfs to access Google Storage&amp;#39;},
 &amp;#39;gdrive&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;gdrivefs.GoogleDriveFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Please install gdrivefs for access to Google Drive&amp;#39;},
 &amp;#39;sftp&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.sftp.SFTPFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;SFTPFileSystem requires &amp;quot;paramiko&amp;quot; to be installed&amp;#39;},
 &amp;#39;ssh&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.sftp.SFTPFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;SFTPFileSystem requires &amp;quot;paramiko&amp;quot; to be installed&amp;#39;},
 &amp;#39;ftp&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.ftp.FTPFileSystem&amp;#39;},
 &amp;#39;hdfs&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.hdfs.PyArrowHDFS&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;pyarrow and local java libraries required for HDFS&amp;#39;},
 &amp;#39;webhdfs&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.webhdfs.WebHDFS&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;webHDFS access requires &amp;quot;requests&amp;quot; to be installed&amp;#39;},
 &amp;#39;s3&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;s3fs.S3FileSystem&amp;#39;, &amp;#39;err&amp;#39;: &amp;#39;Install s3fs to access S3&amp;#39;},
 &amp;#39;adl&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;adlfs.AzureDatalakeFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Install adlfs to access Azure Datalake Gen1&amp;#39;},
 &amp;#39;abfs&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;adlfs.AzureBlobFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&amp;#39;},
 &amp;#39;az&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;adlfs.AzureBlobFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&amp;#39;},
 &amp;#39;cached&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.cached.CachingFileSystem&amp;#39;},
 &amp;#39;blockcache&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.cached.CachingFileSystem&amp;#39;},
 &amp;#39;filecache&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.cached.WholeFileCacheFileSystem&amp;#39;},
 &amp;#39;simplecache&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.cached.SimpleCacheFileSystem&amp;#39;},
 &amp;#39;dask&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.dask.DaskWorkerFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Install dask distributed to access worker file system&amp;#39;},
 &amp;#39;github&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.github.GithubFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Install the requests package to use the github FS&amp;#39;},
 &amp;#39;git&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.git.GitFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Install pygit2 to browse local git repos&amp;#39;},
 &amp;#39;smb&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.smb.SMBFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;SMB requires &amp;quot;smbprotocol&amp;quot; or &amp;quot;smbprotocol[kerberos]&amp;quot; installed&amp;#39;},
 &amp;#39;jupyter&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.jupyter.JupyterFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Jupyter FS requires requests to be installed&amp;#39;},
 &amp;#39;jlab&amp;#39;: {&amp;#39;class&amp;#39;: &amp;#39;fsspec.implementations.jupyter.JupyterFileSystem&amp;#39;,
  &amp;#39;err&amp;#39;: &amp;#39;Jupyter FS requires requests to be installed&amp;#39;}}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you don&amp;#8217;t see your file system supported, there are a few options ranging from writing a new spec for FSSPEC, to using a FUSE filesystem layer, or copying the data to a support file system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since I&amp;#8217;m focused on experimentation, I decided to install all of the extra packages from &lt;a href=&quot;https://github.com/intake/filesystem_spec/blob/master/setup.py&quot;&gt;https://github.com/intake/filesystem_spec/blob/master/setup.py&lt;/a&gt; as part of my Dockerfile in &lt;a href=&quot;#ex_install_all_fs&quot;&gt;[ex_install_all_fs]&lt;/a&gt;. If we just wanted to support our example (reading from http and writing to S3 compatible FS) we could simplify that to &lt;a href=&quot;#ex_install_just_s3_http&quot;&gt;[ex_install_just_s3_http]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ex_install_just_s3_http&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;pip install fsspec&lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt;s3&lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt; aiohttp&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Often distributed file systems require some level of configuration, although sometimes this configuration is &quot;hidden&quot; from the end user so it is not always as visible. With Dask, the configuration needs to be specified along with each reading/writing operation which makes the configuration more visible.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In Hadoop based systems, configuration is often read from a combination of environment variables and mystery XML files, which, when working can feel like magic&amp;#8201;&amp;#8212;&amp;#8201;but keep in mind, the most difficult configuration to debug is the configuration you can not find.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since we&amp;#8217;re pulling our data over public http, we don&amp;#8217;t need special configuration for that. However, for our write side, I&amp;#8217;m using minio (an S3-compatible file system) which needs configuration. The endpoint_url is the service name from &lt;code&gt;helm ls -n minio&lt;/code&gt; plus [namespace].svc.cluster.local. The key and secret are specified during the install (which we did in the previous post).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;minio_storage_options &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; {
    &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;key&amp;quot;&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;YOURACCESSKEY&amp;quot;&lt;/span&gt;,
    &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;secret&amp;quot;&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;YOURSECRETKEY&amp;quot;&lt;/span&gt;,
    &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;client_kwargs&amp;quot;&lt;/span&gt;: {
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;endpoint_url&amp;quot;&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;http://minio-1602984784.minio.svc.cluster.local:9000&amp;quot;&lt;/span&gt;,
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;region_name&amp;quot;&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;us-east-1&amp;#39;&lt;/span&gt;
    },
    &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;config_kwargs&amp;quot;&lt;/span&gt;: {&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;s3&amp;quot;&lt;/span&gt;: {&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;signature_version&amp;quot;&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;s3v4&amp;#39;&lt;/span&gt;}},
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ll use these storage options in the next section when writing data to our MinIO server.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock warning&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Warning&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first time I did this, I was unable to figure out what was going on for a few hours because I had &quot;anon&quot;: &quot;false&quot;, and the false string was automatically converted to the true boolean value.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Sometimes data can also come from or be written to things that are even less like file systems than the web, such as databases. In Dask, these are represented in a way closer to how file formats are represented, which is what we are going to explore next.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_file-formats&quot;&gt;(File) Formats&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dask has built in support for a variety of formats on top of the different file systems. Both the Bag and DataFrame APIs have their own IO functions (&lt;a href=&quot;https://docs.dask.org/en/latest/bag-creation.html&quot;&gt;bag IO&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://docs.dask.org/en/latest/dataframe-api.html#create-dataframes&quot;&gt;dataframe IO&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In our case, the input format we&amp;#8217;ve got is JSON and the target output format is Parquet. Dask DataFrame&amp;#8217;s IO library supports both of those formats so we&amp;#8217;ll use the DataFrame API. We could also do this with the Bag API.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_reading&quot;&gt;Reading&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To load the data we need to specify the files we want to load. On file systems that support listing (like S3, HDFS, local, etc.), we can use wild cards, but when using a file system without listing support we need to create a list of all of the files.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;gh_archive_files&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;[]
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;while&lt;/span&gt; current_date &lt;span style=&quot;color: #666666&quot;&gt;&amp;lt;&lt;/span&gt; datetime&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;datetime&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;now() &lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;  datetime&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;timedelta(days&lt;span style=&quot;color: #666666&quot;&gt;=1&lt;/span&gt;):
    current_date &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; current_date &lt;span style=&quot;color: #666666&quot;&gt;+&lt;/span&gt; datetime&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;timedelta(hours&lt;span style=&quot;color: #666666&quot;&gt;=1&lt;/span&gt;)
    datestring &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; f&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;{current_date.year}-{current_date.month:02}-{current_date.day:02}-{current_date.hour}&amp;#39;&lt;/span&gt;
    gh_url &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; f&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;http://data.githubarchive.org/{datestring}.json.gz&amp;#39;&lt;/span&gt;
    gh_archive_files&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;append(gh_url)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When I have a number of different inputs, I like to start with loading just the first file to explore the schema.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;df &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; dd&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;read_json(gh_archive_files, compression&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;gzip&amp;#39;&lt;/span&gt;)
df&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;columns&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After loading our initial input, calling &quot;head&quot; on the distributed DataFrame lets us see what&amp;#8217;s going on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;df&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;head()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Note the result of doing this (in IPython/Jupyter) is displayed using the normal pandas display logic, resulting in a nice image &lt;a href=&quot;#dfheadimg&quot;&gt;[dfheadimg]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;dfheadimg&quot; class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;../images/a-quick-look-at-df-io-basic-etl-w-json-over-http-to-csv-and-parquet-on-minio-df-head.png&quot; alt=&quot;Image of Dataframe display in the notebook&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you&amp;#8217;ve called &lt;code&gt;df.head&lt;/code&gt; in Spark, you&amp;#8217;ll note this is a much nicer default view. That being said the data needs a bit of cleaning up.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_some-quick-tidying-up&quot;&gt;Some Quick Tidying Up&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As we can see, there is nested JSON data in the DataFrame. I would like to partition on the project name so that, later, we can play around with data per-project without having to load everything (although I don&amp;#8217;t think there is any automated filter push down). However, we can&amp;#8217;t partition using a column that is a nested data structure, so we need to extract the project name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;def&lt;/span&gt; &lt;span style=&quot;color: #0000FF&quot;&gt;clean_record&lt;/span&gt;(record):
    r &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; {
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;repo&amp;quot;&lt;/span&gt;: record[cols&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;get_loc(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;repo&amp;quot;&lt;/span&gt;)],
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;repo_name&amp;quot;&lt;/span&gt;: record[cols&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;get_loc(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;repo&amp;quot;&lt;/span&gt;)][&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;],
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;: record[cols&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;get_loc(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;)],
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt;: record[cols&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;get_loc(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt;)],
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;created_at&amp;quot;&lt;/span&gt;: record[cols&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;get_loc(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;created_at&amp;quot;&lt;/span&gt;)],
        &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;payload&amp;quot;&lt;/span&gt;: record[cols&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;get_loc(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;payload&amp;quot;&lt;/span&gt;)]}
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;return&lt;/span&gt; r

cleaned_up_bag &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; data_bag&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;map(clean_record)
res &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; cleaned_up_bag&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;to_dataframe()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_writes&quot;&gt;Writes&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The write side looks very similar to the read side, but we&amp;#8217;re going to use the minio_storage_options object we created earlier.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;res&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;to_parquet(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;s3://dask-test/boop-test-partioned&amp;quot;&lt;/span&gt;,
              partition_on&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;[&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;repo_name&amp;quot;&lt;/span&gt;], &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Based on &amp;quot; there will be no global groupby.&amp;quot; I think this is the value we want.&lt;/span&gt;
              compression&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;gzip&amp;quot;&lt;/span&gt;,
              storage_options&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;minio_storage_options, engine&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;pyarrow&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Not all of  the Dask formats support partitioned writes. When a format does not support partition_on or other partioned writes, Dask will need to either all of the data back to either a single executor or the client Python process. This can cause failures with large datasets.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_compression&quot;&gt;Compression&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Data is often stored in compressed formats, and the same library used to abstract file system access in Dask also abstracts compression. Some compression algorithms support random reads, but many do not. For people coming from the Hadoop ecosystem this can be thought of as the impact on &quot;splitable.&quot;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Just because the underlying compression algorithm may support random reads does not mean that the FSSPEC wrapper will. Unfortunately, there is no current, easy way to check what a compression format supports besides testing it out or reading the source code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock warning&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Warning&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dask does not support &quot;streaming&quot; non-random access input formats. This means that the data inside a file must be able to fit entirely in memory.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dask I/O integrates pretty well into much of the existing &quot;big data&quot; ecosystem, although the methods of specifying configuration are a little bit different. Some nested data structures can be difficult to represent in certain formats with Dask, although as the Python libraries for these formats continue to improve so will Dask&amp;#8217;s support.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Now that we&amp;#8217;ve got Dask installed, it&amp;#8217;s time to try some simple data preparation and extract, transform, load(ETL). While ETL is often not the most exciting thing, getting data is the first step of most adventures. Data tools don&amp;#8217;t exist in a vacuum; the data normally comes from somewhere else, and the data or models we make need to be useable with other tools. Because of this, the formats and systems that a tool can interact with can make a difference between it being a fit or needing to keep looking. To simplify your life with I/O, you should make sure your notebook (or client) runs inside the same cluster as the workers.</summary></entry><entry><title type="html">Tagging my ARM NVidia Jetson machines with GPUs in my Kubernetes (k3s) cluster</title><link href="https://scalingpythonml.com/2021/02/22/tagging-arm-nvidia-jetson-machines-with-gpus-in-my-k3s-cluster.html" rel="alternate" type="text/html" title="Tagging my ARM NVidia Jetson machines with GPUs in my Kubernetes (k3s) cluster" /><published>2021-02-22T00:00:00-08:00</published><updated>2021-02-22T00:00:00-08:00</updated><id>https://scalingpythonml.com/2021/02/22/tagging-arm-nvidia-jetson-machines-with-gpus-in-my-k3s-cluster</id><content type="html" xml:base="https://scalingpythonml.com/2021/02/22/tagging-arm-nvidia-jetson-machines-with-gpus-in-my-k3s-cluster.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We previously setup the cluster with GPUs, but since we want to get into using GPU acceleration, it&amp;#8217;s important to be able to request these resources from the Kubernetes scheduler. Tagging the nodes will help Kubernetes tell the different between the Raspbery Pi and Jetson Xavier in &lt;a href=&quot;#my-cluster-img&quot;&gt;[my-cluster-img]&lt;/a&gt;. Depending on your type of GPUs there are options for automatically labeling your nodes. Since I&amp;#8217;ve got NVidia boards we&amp;#8217;ll use the k8s-device-plugin to do the labeling of the nodes. For our machines, though, the containers out of the box do not run on ARM and the code does not detect Jetson chips.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;my-cluster-img&quot; class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/images/pi-and-jetson-IMG_0629.jpg&quot; alt=&quot;Image of Raspbery Pis on top with Jetson Xaviers down bellow&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_disabling-un-needed-checks&quot;&gt;Disabling un-needed checks&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Wind River folks have &lt;a href=&quot;https://blogs.windriver.com/wind_river_blog/2020/06/nvidia-k8s-device-plugin-for-wind-river-linux/&quot;&gt; published a series of patches for NVidia&lt;/a&gt; and instructions. You can apply these patches by running the commands in &lt;a href=&quot;#pathc_ex&quot;&gt;[pathc_ex]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;patch_ex&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 1. Apply the Wind River patches to the ARM tagging.&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;patch -p1 &amp;lt; &lt;span style=&quot;color: #666666&quot;&gt;0001&lt;/span&gt;-arm64-add-support-for-arm64-architectures.patch
patch -p1 &amp;lt; &lt;span style=&quot;color: #666666&quot;&gt;0002&lt;/span&gt;-nvidia-Add-support-for-tegra-boards.patch&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The third patch doesn&amp;#8217;t quite apply cleanly, as the loading NVML code has changed a bit (namely, failOnInitErrorFlag has been added). However, if you take a look at the patch, you can manually apply it by looking for the &quot;log.Println(&quot;Loading NVML&quot;)&quot; statement and replacing that chunk of code with the new code (indicated by the +s in the patch file).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_building-the-arm-image&quot;&gt;Building the arm image&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Building the image with ARM support is now relatively simple. If you&amp;#8217;re running on an ARM machine you can just build as normal, e.g. &lt;code&gt;docker build -t holdenk/k8s-device-plugin-arm:v0.7.0.1 -f ./docker/arm64/Dockerfile.ubuntu16.04 .&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Otherwise, assuming you&amp;#8217;ve set up cross-building, you can use buildx and just specify one platform, &lt;code&gt;docker buildx build -t holdenk/k8s-device-plugin-arm:v0.7.0.1 --platform linux/arm64 --push -f ./docker/arm64/Dockerfile.ubuntu16.04 .&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_building-a-multi-arch-image&quot;&gt;Building a multi-arch image&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you have a mix of ARM and x86 machines in your cluster (as I do), having just an ARM image makes deployment a bit difficult. Thankfully we can update the Dockerfile to make it multi-arch by adding the &lt;code&gt;ARG TARGETARCH&lt;/code&gt; and taking out the hardcoded arm64 references. For the &lt;code&gt;--platform=arm64&lt;/code&gt; we can just go ahead and remove them, and for the wget, we can replace &lt;code&gt;arm64&lt;/code&gt; with &lt;code&gt;${TARGETARCH}&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now, assuming you&amp;#8217;ve got your multi-arch Docker build environment set up, you can cross-build this with, &lt;code&gt;docker buildx build -t holdenk/k8s-device-plugin:v0.7.0.1 --platform linux/arm64,linux/amd64 --push -f ./docker/multi/Dockerfile.ubuntu16.04 .&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_updating-the-yaml-deploying&quot;&gt;Updating the YAML &amp;amp; deploying.&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once you&amp;#8217;ve built your container image, you&amp;#8217;ll need to update the image in &lt;code&gt;nvidia-device-plugin.yml&lt;/code&gt; to point to your custom version. You can then deploy it with &lt;code&gt;kubectl apply -f nvidia-device-plugin.yml&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Tagging your nodes with GPU resources is an important part of being able to take advantage of your cluster resources. While the NVidia tagger does not yet support Jetson boards out of the box, there are only a few small patches needed to get it working.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">We previously setup the cluster with GPUs, but since we want to get into using GPU acceleration, it&amp;#8217;s important to be able to request these resources from the Kubernetes scheduler. Tagging the nodes will help Kubernetes tell the different between the Raspbery Pi and Jetson Xavier in [my-cluster-img]. Depending on your type of GPUs there are options for automatically labeling your nodes. Since I&amp;#8217;ve got NVidia boards we&amp;#8217;ll use the k8s-device-plugin to do the labeling of the nodes. For our machines, though, the containers out of the box do not run on ARM and the code does not detect Jetson chips.</summary></entry><entry><title type="html">Running Spark Jupyter Notebooks Client Mode inside of a Kubernetes Cluster (with ARM for Extra Fun)</title><link href="https://scalingpythonml.com/2020/12/21/running-a-spark-jupyter-notebooks-in-client-mode-inside-of-a-kubernetes-cluster-on-arm.html" rel="alternate" type="text/html" title="Running Spark Jupyter Notebooks Client Mode inside of a Kubernetes Cluster (with ARM for Extra Fun)" /><published>2020-12-21T00:00:00-08:00</published><updated>2020-12-21T00:00:00-08:00</updated><id>https://scalingpythonml.com/2020/12/21/running-a-spark-jupyter-notebooks-in-client-mode-inside-of-a-kubernetes-cluster-on-arm</id><content type="html" xml:base="https://scalingpythonml.com/2020/12/21/running-a-spark-jupyter-notebooks-in-client-mode-inside-of-a-kubernetes-cluster-on-arm.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Having your Spark Notebook inside the same cluster as the executors can reduce network errors and improve uptime. Since these network issues can result in job failure, this is an important consideration. This post assumes that you&amp;#8217;ve already set up the foundation JupyterHub inside of Kubernetes deployment; &lt;a href=&quot;https://scalingpythonml.com/2020/12/12/deploying-jupyter-lab-notebook-for-dask-on-arm-on-k8s.html&quot;&gt;the Dask-distributed notebook blog post covers that if you haven&amp;#8217;t&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I like to think of this as washing my dog (Timbit) is a lot easier inside of the bath-tun than trying to wash him outside. Although it can take a bit of work to get him inside the tub &lt;a href=&quot;#timbit-tub-img&quot;&gt;[timbit-tub-img]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;timbit-tub-img&quot; class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/images/timbit-in-the-tub-IMG_0589.jpg&quot; alt=&quot;Timbit in the bath tub&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you&amp;#8217;re interested my &lt;a href=&quot;https://www.youtube.com/watch?v=a7hDZxisuAk&amp;amp;list=PLRLebp9QyZtapJnz4cpDctnQ1i_qUmeap&amp;amp;index=1&quot;&gt;YouTube playlist of Get Spark Working with Notebook inside my Kubernetes (K8s/K3s) ARM cluster &lt;/a&gt; shows the journey I went on to get this working.
A lot of my blog posts come out of my &lt;a href=&quot;https://www.youtube.com/user/holdenkarau&quot;&gt;Open Source Live Streams&lt;/a&gt; (which even include Timbit sometimes).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To get a Spark notebook working inside of the cluster, we need to set up a few different things. The first step, similar to dask-kubernetes, is building a container with Jupyter and Spark installed. We also need to make a container of Spark for the executors. In addition to the containers, we need to set up permissions on the cluster and ensure that the executors that your Spark driver will launch have a way to talk to the driver in the notebook.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It may seem like there are extra steps here compared to dask-kubernetes. Dask-kubernetes automates some service creation, which allows for communication between the scheduler, executors, and the notebook.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_building-the-containers&quot;&gt;Building the Containers&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We need two containers, one with Jupyter and Spark installed together and another with just Spark. Since we&amp;#8217;re working in Python, there are some extra Python libraries we want to install as well (PyArrow, pandas, etc.) If you&amp;#8217;ve got a specific version of a library that your project depends on, you&amp;#8217;ll want to add it to both the Jupyter Spark driver container and the executor containers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To start with we&amp;#8217;ll download &lt;a href=&quot;http://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; and decompress it, as shown in &lt;a href=&quot;#dlspark&quot;&gt;Download Spark&lt;/a&gt;, so that we can copy the desired parts inside our containers.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;dlspark&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 1. Download Spark&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;if&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; ! -f spark-3.1.1-bin-hadoop3.2.tgz &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;then&lt;/span&gt;
  axel https://ftp.wayne.edu/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;fi&lt;/span&gt;
rm -rf spark-3.1.1-bin-hadoop-3.2
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;if&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; ! -d spark-3.1.1-bin-hadoop3.2 &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;then&lt;/span&gt;
  tar -xvf spark-3.1.1-bin-hadoop3.2.tgz
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;fi&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Set SPARK_HOME to extracted directory&lt;/span&gt;
&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;`&lt;/span&gt;&lt;span style=&quot;color: #008000&quot;&gt;pwd&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;`&lt;/span&gt;/spark-3.1.1-bin-hadoop3.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that we have Spark downloaded we can start customizing our &lt;code&gt;Dockerfiles&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_building-the-jupyter-spark-container&quot;&gt;Building the Jupyter Spark Container&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The easiest way to build a Jupyter Spark container is to install Spark on top of the base Jupyter container. If you&amp;#8217;re running on ARM, you&amp;#8217;ll need to first cross-build the base Jupyter container (see my &lt;a href=&quot;https://scalingpythonml.com/2020/12/12/deploying-jupyter-lab-notebook-for-dask-on-arm-on-k8s.html&quot;&gt;instructions in the previous post&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In my case I&amp;#8217;ve custom built the &lt;a href=&quot;https://github.com/jupyterhub/zero-to-jupyterhub-k8s/tree/master/images/singleuser-sample&quot;&gt;single-user sample Docker container&lt;/a&gt; from zero-to-jupyterhub-k8s to &lt;code&gt;holdenk/jupyter-hub-magicsingleuser-sample:0.10.2&lt;/code&gt; as I needed ARM support. If you don&amp;#8217;t need to cross-build your custom container, you can use the pre-built container at &lt;code&gt;jupyterhub/k8s-singleuser-sample&lt;/code&gt; as the basis for yours.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since Spark needs Java to run, I decided to look at the &lt;a href=&quot;https://github.com/docker-library/openjdk/blob/master/11/jdk/slim-buster/Dockerfile&quot;&gt;jdk11 slim dockerfile&lt;/a&gt; to see how to install Java in a dockerfile well. If you&amp;#8217;re an object-oriented person, you might be wishing we had multiple-inheritence with Dockerfiles, but that doesn&amp;#8217;t work. In addition to the JDK11 dockerfile, I looked at Spark&amp;#8217;s own Dockerfiles (includign PySpark) and the resulting Juptyer Spark Container specification is shown in &lt;a href=&quot;#spark_notebook_dockerfile&quot;&gt;Dockerfile to add Spark on top of the Jupyter Notebook container.&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;spark_notebook_dockerfile&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 2. Dockerfile to add Spark on top of the Jupyter Notebook container.&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;dockerfile&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;FROM&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; holdenk/jupyter-hub-magicsingleuser-sample:0.10.2-n412.h25a21283&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Switch to root to install stuff&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; root&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Use multiple cores to compile the C code :)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; MAKEFLAGS -j &lt;span style=&quot;color: #666666&quot;&gt;4&lt;/span&gt;


&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #008000&quot;&gt;set&lt;/span&gt; -eux; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get update &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get install -yq graphviz git build-essential cmake telnet &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    ln -s /lib /lib64 &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt install -y bash tini libc6 libpam-modules krb5-user libnss3 procps ca-certificates p11-kit wget bzip2 git mercurial subversion &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mkdir -p /opt/spark &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mkdir -p /opt/spark/examples &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mkdir -p /opt/spark/work-dir &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    touch /opt/spark/RELEASE &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    rm /bin/sh &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    ln -sv /bin/bash /bin/sh &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;auth required pam_wheel.so use_uid&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/pam.d/su &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    chgrp root /etc/passwd &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod ug+rw /etc/passwd &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    conda install -c conda-forge --yes mamba &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;python&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.8.6 &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    pip install --upgrade pip setuptools &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;numpy&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==1&lt;/span&gt;.19.2 pandas cytoolz numba lz4 scikit-build python-blosc&lt;span style=&quot;color: #666666&quot;&gt;=1&lt;/span&gt;.9.2 &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes pyarrow &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt;  pip install -vvv pyarrow&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get clean &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    rm -rf /var/cache/apt/* &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    rm -rf /var/lib/apt/lists/* &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; -e &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$NB_USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;\n&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$NB_USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; | passwd &lt;span style=&quot;color: #19177C&quot;&gt;$NB_USER&lt;/span&gt;



&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Based on https://github.com/docker-library/openjdk/blob/master/11/jdk/slim-buster/Dockerfile&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Default to UTF-8 file.encoding&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; LANG C.UTF-8

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; JAVA_HOME /usr/local/openjdk-11
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; PATH &lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin:&lt;span style=&quot;color: #19177C&quot;&gt;$PATH&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;{&lt;/span&gt; &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;#/bin/sh&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;echo &amp;quot;$JAVA_HOME&amp;quot;&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #666666&quot;&gt;}&lt;/span&gt; &amp;gt; /usr/local/bin/docker-java-home &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x /usr/local/bin/docker-java-home &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;docker-java-home&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; JAVA_VERSION &lt;span style=&quot;color: #666666&quot;&gt;11&lt;/span&gt;.0.9.1

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #008000&quot;&gt;set&lt;/span&gt; -eux; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# this &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;case&amp;quot;&lt;/span&gt; statement is generated via &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;update.sh&amp;quot;&lt;/span&gt;
	&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;case&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$arch&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; in &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# arm64v8
		arm64 | aarch64&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;downloadUrl&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;https://github.com/AdoptOpenJDK/openjdk11-upstream-binaries/releases/download/jdk-11.0.9.1%2B1/OpenJDK11U-jdk_aarch64_linux_11.0.9.1_1.tar.gz ;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# amd64
		amd64 | i386:x86-64&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;downloadUrl&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;https://github.com/AdoptOpenJDK/openjdk11-upstream-binaries/releases/download/jdk-11.0.9.1%2B1/OpenJDK11U-jdk_x64_linux_11.0.9.1_1.tar.gz ;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# fallback
		*&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &amp;gt;&amp;amp;&lt;span style=&quot;color: #666666&quot;&gt;2&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;error: unsupported architecture: &amp;#39;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$arch&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #008000&quot;&gt;exit&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;1&lt;/span&gt; ;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;esac&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #19177C&quot;&gt;savedAptMark&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;apt-mark showmanual&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	apt-get update; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	apt-get install -y --no-install-recommends &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		dirmngr &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		gnupg &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		wget &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	rm -rf /var/lib/apt/lists/*; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	wget -O openjdk.tgz.asc &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$downloadUrl&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;.sign&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	wget -O openjdk.tgz &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$downloadUrl&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; --progress&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;dot:giga; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #008000&quot;&gt;export&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;GNUPGHOME&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;mktemp -d&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# TODO find a good link &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;for&lt;/span&gt; users to verify this key is right &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;https://mail.openjdk.java.net/pipermail/jdk-updates-dev/2019-April/000951.html is one of the only mentions of it I can find&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;; perhaps a note added to https://adoptopenjdk.net/upstream.html would make sense?
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# no-self-sigs-only: https://salsa.debian.org/debian/gnupg2/commit/c93ca04a53569916308b369c8b218dad5ae8fe07&lt;/span&gt;
	gpg --batch --keyserver ha.pool.sks-keyservers.net --keyserver-options no-self-sigs-only --recv-keys CA5F11C6CE22644D42C6AC4492EF8D39DC13168F; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# also verify that key was signed by Andrew Haley &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;the OpenJDK &lt;span style=&quot;color: #666666&quot;&gt;8&lt;/span&gt; and &lt;span style=&quot;color: #666666&quot;&gt;11&lt;/span&gt; Updates OpenJDK project lead&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# (https://github.com/docker-library/openjdk/pull/322#discussion_r286839190)&lt;/span&gt;
	gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys EAC843EBD3EFDB98CC772FADA5CD6035332FA671; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	gpg --batch --list-sigs --keyid-format 0xLONG CA5F11C6CE22644D42C6AC4492EF8D39DC13168F &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		| tee /dev/stderr &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		| grep &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0xA5CD6035332FA671&amp;#39;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		| grep &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;Andrew Haley&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	gpg --batch --verify openjdk.tgz.asc openjdk.tgz; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	gpgconf --kill all; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	rm -rf &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$GNUPGHOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	mkdir -p &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	tar --extract &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		--file openjdk.tgz &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		--directory &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		--strip-components &lt;span style=&quot;color: #666666&quot;&gt;1&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		--no-same-owner &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	rm openjdk.tgz*; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# TODO strip &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;demo&amp;quot;&lt;/span&gt; and &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;man&amp;quot;&lt;/span&gt; folders?
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	apt-mark auto &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;.*&amp;#39;&lt;/span&gt; &amp;gt; /dev/null; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; -z &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$savedAptMark&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; apt-mark manual &lt;span style=&quot;color: #19177C&quot;&gt;$savedAptMark&lt;/span&gt; &amp;gt; /dev/null; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;false; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# update &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;cacerts&amp;quot;&lt;/span&gt; bundle to use Debian&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;s CA certificates (and make sure it stays up-to-date with changes to Debian&amp;#39;&lt;/span&gt;s store&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# see https://github.com/docker-library/openjdk/issues/327&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#     http://rabexc.org/posts/certificates-not-working-java#comment-4099504075&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#     https://salsa.debian.org/java-team/ca-certificates-java/blob/3e51a84e9104823319abeb31f880580e46f45a98/debian/jks-keystore.hook.in&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#     https://git.alpinelinux.org/aports/tree/community/java-cacerts/APKBUILD?id=761af65f38b4570093461e6546dcf6b179d2b624#n29&lt;/span&gt;
	&lt;span style=&quot;color: #666666&quot;&gt;{&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;#!/usr/bin/env bash&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;set -Eeuo pipefail&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;if ! [ -d &amp;quot;$JAVA_HOME&amp;quot; ]; then echo &amp;gt;&amp;amp;2 &amp;quot;error: missing JAVA_HOME environment variable&amp;quot;; exit 1; fi&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# &lt;span style=&quot;color: #666666&quot;&gt;8&lt;/span&gt;-jdk uses &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;/jre/lib/security/cacerts&amp;quot;&lt;/span&gt; and &lt;span style=&quot;color: #666666&quot;&gt;8&lt;/span&gt;-jre and &lt;span style=&quot;color: #666666&quot;&gt;11&lt;/span&gt;+ uses &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;/lib/security/cacerts&amp;quot;&lt;/span&gt; directly &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;no &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;jre&amp;quot;&lt;/span&gt; directory&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
		&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;cacertsFile=; for f in &amp;quot;$JAVA_HOME/lib/security/cacerts&amp;quot; &amp;quot;$JAVA_HOME/jre/lib/security/cacerts&amp;quot;; do if [ -e &amp;quot;$f&amp;quot; ]; then cacertsFile=&amp;quot;$f&amp;quot;; break; fi; done&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;if [ -z &amp;quot;$cacertsFile&amp;quot; ] || ! [ -f &amp;quot;$cacertsFile&amp;quot; ]; then echo &amp;gt;&amp;amp;2 &amp;quot;error: failed to find cacerts file in $JAVA_HOME&amp;quot;; exit 1; fi&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
		&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;trust extract --overwrite --format=java-cacerts --filter=ca-anchors --purpose=server-auth &amp;quot;$cacertsFile&amp;quot;&amp;#39;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #666666&quot;&gt;}&lt;/span&gt; &amp;gt; /etc/ca-certificates/update.d/docker-openjdk; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	chmod +x /etc/ca-certificates/update.d/docker-openjdk; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	/etc/ca-certificates/update.d/docker-openjdk; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# https://github.com/docker-library/openjdk/issues/331#issuecomment-498834472
	find &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$JAVA_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;/lib&amp;quot;&lt;/span&gt; -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.so&amp;#39;&lt;/span&gt; -exec dirname &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;{}&amp;#39;&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;;&amp;#39;&lt;/span&gt; | sort -u &amp;gt; /etc/ld.so.conf.d/docker-openjdk.conf; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	ldconfig; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
# basic smoke test
	&lt;span style=&quot;color: #19177C&quot;&gt;fileEncoding&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;System.out.println(System.getProperty(&amp;quot;file.encoding&amp;quot;))&amp;#39;&lt;/span&gt; | jshell -s -&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$fileEncoding&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;UTF-8&amp;#39;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;; rm -rf ~/.java; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	javac --version; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
	java --version


&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Based on the Spark dockerfile&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; jars /opt/spark/jars
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; bin /opt/spark/bin
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; sbin /opt/spark/sbin
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; kubernetes/dockerfiles/spark/entrypoint.sh /opt/
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Wildcard so it covers decom.sh present (3.1+) and not present (pre-3.1)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; kubernetes/dockerfiles/spark/decom.sh* /opt/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; examples /opt/spark/examples
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; kubernetes/tests /opt/spark/tests
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; data /opt/spark/data
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# We need to copy over the license file so we can pip install PySpark&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; LICENSE /opt/spark/LICENSE
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; licenses /opt/spark/licenses

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; SPARK_HOME /opt/spark

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Note: don&amp;#39;t change the workdir since then your Jupyter notebooks won&amp;#39;t persist.&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; chmod g+w /opt/spark/work-dir
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Wildcard so it covers decom.sh present (3.1+) and not present (pre-3.1)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; chmod a+x /opt/decom.sh* &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;No decom script present, assuming pre-3.1&amp;quot;&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Copy pyspark with setup files and everything&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; python &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/python

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Add PySpark to PYTHON_PATH&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; pip install -e &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/python

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Add S3A support&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.563/aws-java-sdk-bundle-1.11.563.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.0/hadoop-aws-3.2.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#tag::iceberg[]&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3-runtime/0.11.0/iceberg-spark3-runtime-0.11.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3-extensions/0.11.0/iceberg-spark3-extensions-0.11.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3/0.11.0/iceberg-spark3-0.11.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-parquet/0.11.0/iceberg-parquet-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-core/0.11.0/iceberg-core-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-arrow/0.11.0/iceberg-arrow-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-data/0.11.0/iceberg-data-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#end::iceberg[]&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; chmod a+rx &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/*.jar 


&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Switch to the user back to a non-root user that will actually do the running&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; $NB_USER&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Should match the service&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;EXPOSE&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; 2222&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;EXPOSE&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; 7777&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since the Dockerfile copies parts of Spark in, remember to save it at the root of where you decompressed the Spark tarball.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you&amp;#8217;re not cross building, you can build this with a regular &lt;code&gt;docker build&lt;/code&gt;, in my case since I&amp;#8217;m targetting arm and x86 I did built it as shown in &lt;a href=&quot;#build_spark_nb&quot;&gt;Build Spark notebook container&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;build_spark_nb&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 3. Build Spark notebook container&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;docker buildx build -t holdenk/spark-notebook:v&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_VERSION&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;  --platform linux/arm64,linux/amd64 --push .&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;An alternative would have been to take the JDK-11 containers as a starting point, and install Jupyter on top of it, but when I tried that I found it more complicated.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This gives us a container with both Spark and the base notebook layer together. For the executors, we don&amp;#8217;t want to bother shipping Jupyter, so we&amp;#8217;ll build a seperate container for the executors.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_building-the-executor-container&quot;&gt;Building the Executor Container&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Spark does not ship pre-built containers for its executors, so regardless of which arch youre using, you will need to build the executor containers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you&amp;#8217;re building multi-arch containers, you will need to update Spark&amp;#8217;s docker image tool. You will need to change the buildx option to push the images by adding &quot;--push&quot; to the docker buildx commands in the script for ./bin/docker-image-tool.sh.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Spark&amp;#8217;s Python container Dockerfile installs an older version of Python without any dependencies, so you will want to customize your Python container setup, as well. My Dockerfile is shown in &lt;a href=&quot;#spark_exec_dockerfile&quot;&gt;Dockerfile customizing PySpark setup&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;spark_exec_dockerfile&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 4. Dockerfile customizing PySpark setup&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;dockerfile&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Licensed to the Apache Software Foundation (ASF) under one or more&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# contributor license agreements.  See the NOTICE file distributed with&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# this work for additional information regarding copyright ownership.&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# The ASF licenses this file to You under the Apache License, Version 2.0&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# (the &amp;quot;License&amp;quot;); you may not use this file except in compliance with&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# the License.  You may obtain a copy of the License at&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#    http://www.apache.org/licenses/LICENSE-2.0&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Unless required by applicable law or agreed to in writing, software&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# See the License for the specific language governing permissions and&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# limitations under the License.&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ARG&lt;/span&gt; base_img

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;FROM&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; $base_img&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;WORKDIR&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; /&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Reset to root to run installation tasks&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; 0&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; PATH /opt/conda/bin:&lt;span style=&quot;color: #19177C&quot;&gt;$PATH&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; mkdir &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/python

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; apt-get update --fix-missing &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get install -yq graphviz git build-essential cmake telnet &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt install -y bash tini libc6 libpam-modules krb5-user libnss3 procps ca-certificates p11-kit wget bzip2 git mercurial subversion &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    rm /bin/sh &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    ln -sv /bin/bash /bin/sh

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; bin/pysetup.sh /pysetup.sh 
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; chmod a+x /pysetup.sh &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ./pysetup.sh
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; conda install -c conda-forge --yes mamba &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;python&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.8.6 &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    pip install --upgrade pip setuptools &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;numpy&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==1&lt;/span&gt;.19.2 pandas cytoolz numba lz4 scikit-build python-blosc&lt;span style=&quot;color: #666666&quot;&gt;=1&lt;/span&gt;.9.2 &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes pyarrow &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt;  pip install -vvv pyarrow&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# s3a support&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#tag::s3a[]&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.0/hadoop-aws-3.2.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.563/aws-java-sdk-bundle-1.11.563.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#end::s3a[]&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#tag::iceberg[]&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3-runtime/0.11.0/iceberg-spark3-runtime-0.11.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3-extensions/0.11.0/iceberg-spark3-extensions-0.11.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ADD&lt;/span&gt; https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark3/0.11.0/iceberg-spark3-0.11.0.jar &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-parquet/0.11.0/iceberg-parquet-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-core/0.11.0/iceberg-core-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-arrow/0.11.0/iceberg-arrow-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#ADD https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-data/0.11.0/iceberg-data-0.11.0.jar ${SPARK_HOME}/jars/&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#end::iceberg[]&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#tag::perms[]&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; chmod a+rx &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/jars/*.jar
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#end::perms[]&lt;/span&gt;


&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; python/pyspark &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/python/pyspark
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; python/lib &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/python/lib

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;WORKDIR&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; /opt/spark/work-dir&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENTRYPOINT&lt;/span&gt; [ &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;/opt/entrypoint.sh&amp;quot;&lt;/span&gt; ]

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Specify the User that the actual main process will run as&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ARG&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;spark_uid&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=185&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; ${spark_uid}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You&amp;#8217;ll see this file references &lt;code&gt;pysetup.sh&lt;/code&gt; which installs Python using Miniforge so we can support arm as shown in &lt;a href=&quot;#pysetupsh&quot;&gt;Setup python&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;pysetupsh&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 5. Setup python&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span style=&quot;color: #008000&quot;&gt;set&lt;/span&gt; -ex
&lt;span style=&quot;color: #008000&quot;&gt;export&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;uname -m&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;if&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$arch&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;==&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;aarm64&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;then&lt;/span&gt;
  &lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;arm64&amp;quot;&lt;/span&gt;;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;fi&lt;/span&gt;
wget --quiet https://github.com/conda-forge/miniforge/releases/download/4.8.5-1/Miniforge3-4.8.5-1-Linux-&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;.sh -O ~/miniforge.sh
chmod a+x ~/miniforge.sh
~/miniforge.sh -b -p /opt/conda
/opt/conda/bin/conda clean -tipsy
ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh
&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;. /opt/conda/etc/profile.d/conda.sh&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bashrc
&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;conda activate base&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bashrc
&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;. /opt/conda/etc/profile.d/conda.sh&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/bash.bashrc
&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;conda activate base&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/bash.bashrc
&lt;span style=&quot;color: #008000&quot;&gt;source&lt;/span&gt; ~/.bashrc
find /opt/conda/ -follow -type f -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.a&amp;#39;&lt;/span&gt; -delete
find /opt/conda/ -follow -type f -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.js.map&amp;#39;&lt;/span&gt; -delete
/opt/conda/bin/conda clean -afy
/opt/conda/bin/conda install --yes nomkl cytoolz cmake tini
/opt/conda/bin/conda init bash
/opt/conda/bin/conda install --yes mamba&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You will want to make your Dockerfile install the dependencies for your program while making sure to select the same version of Python that you have in your Jupyter container, so you may need to modify those two examples.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once you&amp;#8217;ve configured your enviroment, you can build your Spark image using the &lt;code&gt;docker-image-tool&lt;/code&gt; that ships with Spark as shown in &lt;a href=&quot;#build_exec_containers&quot;&gt;[build_exec_containers]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;build_exec_contianers&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 6. Build the exec containers&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Copy over python setup script so we can have matching pythons&lt;/span&gt;
&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_VERSION&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=3&lt;/span&gt;.1.1.11
cp pysetup.sh &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;/bin/
&lt;span style=&quot;color: #008000&quot;&gt;pushd&lt;/span&gt; &lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;
&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_ROOT&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$SPARK_HOME&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;
./bin/docker-image-tool.sh  -r holdenk -t v&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;SPARK_VERSION&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt; -X -b &lt;span style=&quot;color: #19177C&quot;&gt;java_image_tag&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=11&lt;/span&gt;-jre-slim -p PyDockerfile Dockerfile build&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock warning&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Warning&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Some parts of Spark may assume a specific layout of the container, e.g. in Spark 3.1 the decommissioning integration makes certain assumptions, so be careful when making changes.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_setting-up-kubernetes-permissions&quot;&gt;Setting up Kubernetes Permissions&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The driver program needs the ability to launch new pods for executors. To allow launching, create a service account or give permissions to the default service account (SA) . In my case, I decided to add permissions to the &quot;dask&quot; service account since the JupyterHub launcher (covered later) doesn&amp;#8217;t support different service accounts depending on the notebook. I also created a special &quot;spark&quot; namespace to make it easier to watch what was happening. My namespace and SA setup is shown in &lt;a href=&quot;#setupsa&quot;&gt;Setup up namespace and service account&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;setupsa&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 7. Setup up namespace and service account&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;kubectl create serviceaccount -n jhub spark
kubectl create namespace spark
kubectl create rolebinding spark-role --clusterrole&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;edit --serviceaccount&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;jhub:spark --namespace&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;spark
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# We can&amp;#39;t override SA in the launcher on per-container basis, so since I&amp;#39;ve already got a dask SA.&lt;/span&gt;
kubectl create rolebinding spark-role-to-dask-acc --clusterrole&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;edit --serviceaccount&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;jhub:dask --namespace&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;spark&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_creating-a-service-allowing-driver-executor-communication&quot;&gt;Creating a Service (Allowing Driver-Executor Communication)&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Spark depends on the executors connecting back to the driver for both the driver its self and the driver&amp;#8217;s BlockManager. If your driver is in a different namespace, the easiest way to allow communication is to create a service to let the executors connect to the driver.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;drvier_svc&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 8. The Spark Driver Service&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;apiVersion: v1
kind: Service
metadata:
  name: driver-service
spec:
  selector:
    app: jupyterhub
    component: singleuser-server
  ports:
    - name: driver
      protocol: TCP
      port: &lt;span style=&quot;color: #666666&quot;&gt;2222&lt;/span&gt;
      targetPort: &lt;span style=&quot;color: #666666&quot;&gt;2222&lt;/span&gt;
    - name: blockmanager
      protocol: TCP
      port: &lt;span style=&quot;color: #666666&quot;&gt;7777&lt;/span&gt;
      targetPort: &lt;span style=&quot;color: #666666&quot;&gt;7777&lt;/span&gt;
  type: ClusterIP&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;drvier_svc_apply&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 9. Apply the Spark Driver Service&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;kubectl apply -n jhub -f driver-service.yaml&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;These port numbers are arbitrary (you can pick different ones), but you&amp;#8217;ll need to remember them when configuring your SparkContext.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_configuring-your-jupyterhub-launcher&quot;&gt;Configuring Your JupyterHub Launcher&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that you have all of the foundational components set up, it&amp;#8217;s time to add them to your JupyterHub launcher. I did this by adding the &lt;code&gt;Spark 3.0.1&lt;/code&gt; option to the &lt;code&gt;profileList&lt;/code&gt; in my &lt;code&gt;config.yaml&lt;/code&gt; shown in &lt;a href=&quot;#my-jupyter-config&quot;&gt;[my-jupyter-config]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;spark-jupyter-config&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 10. Combined Spark and Dask Jupyter Config&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hub&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magichub
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;proxy&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;service&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;type&lt;/span&gt;: NodePort
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretToken&lt;/span&gt;: DIFFERENTSECRET
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretSync&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicsecret-sync
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;chp&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jconfigurable-http-proxy
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.0.1&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ingress&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;enabled&lt;/span&gt;: true
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hosts&lt;/span&gt;:
    - holdenkarau.mooo.com
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tls&lt;/span&gt;:
   - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hosts&lt;/span&gt;:
      - holdenkarau.mooo.com
     &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretName&lt;/span&gt;: k3s-mooo-tls
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;singleuser&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;serviceAccountName&lt;/span&gt;: dask
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;networkTools&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicnetwork-tools
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicsingleuser-sample
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;profileList&lt;/span&gt;:
    - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;display_name&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;Minimal&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;environment&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;description&lt;/span&gt;: &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;&amp;quot;To avoid too much bells and whistles&lt;/span&gt;: Python.&amp;quot;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;default&lt;/span&gt;: true
    - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;display_name&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;Dask&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;container&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;description&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;If&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;you&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;want&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;to&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;run&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;dask&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kubespawner_override&lt;/span&gt;:
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;: holdenk/dask-notebook:v0.9.4b
    - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;display_name&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;Spark&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;3.0.1&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;container&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;description&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;If&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;you&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;want&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;to&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;run&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;Spark&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kubespawner_override&lt;/span&gt;:
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;: holdenk/spark-notebook:v3.0.1.1
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;prePuller&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hook&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicimage-awaiter
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Do something better here! It&amp;#39;s being reworked though - https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues/1871&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;auth&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;type&lt;/span&gt;: dummy
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;dummy&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;password&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;mypassword&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;whitelist&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;users&lt;/span&gt;:
      - user1
      - user2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can then upgrade your previous deployment with &lt;code&gt;helm upgrade --cleanup-on-fail   --install $RELEASE jupyterhub/jupyterhub   --namespace $NAMESPACE   --create-namespace   --version=0.10.2   --values config.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_configuring-your-spakcontext&quot;&gt;Configuring Your SpakContext&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that you can launch a notebook with everything needed for Spark, it&amp;#8217;s time to talk about configuring your SparkContext to work in this environment. You&amp;#8217;ll need more configuration than you can get through the SparkContext constructor directly, so you will also need to import the SparkConf. Your imports might look like &lt;a href=&quot;#sparkImports&quot;&gt;Spark Imports&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sparkImports&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 11. Spark Imports&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;from&lt;/span&gt; &lt;span style=&quot;color: #0000FF; font-weight: bold&quot;&gt;pyspark&lt;/span&gt; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;import&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;*&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;from&lt;/span&gt; &lt;span style=&quot;color: #0000FF; font-weight: bold&quot;&gt;pyspark.context&lt;/span&gt; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;import&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;*&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;from&lt;/span&gt; &lt;span style=&quot;color: #0000FF; font-weight: bold&quot;&gt;pyspark.conf&lt;/span&gt; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;import&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;*&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In my cluster, the K8s API is available at &lt;code&gt;&lt;a href=&quot;https://kubernetes.default&quot; class=&quot;bare&quot;&gt;https://kubernetes.default&lt;/a&gt;&lt;/code&gt;, so I start my configuration as in &lt;a href=&quot;#makeSparkConf&quot;&gt;Start of Spark Conf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;makeSparkConf&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 12. Start of Spark Conf&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;conf &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; (SparkConf()&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;setMaster(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;k8s://https://kubernetes.default&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since there are no pre-built docker images for Spark, you&amp;#8217;ll need to configure the container image used for the executor, mine is shown in &lt;a href=&quot;#configContainer&quot;&gt;Configure Container&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;configContainer&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 13. Configure Container&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;    &lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark.kubernetes.container.image&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;holdenk/spark-py:v3.0.1.2&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Normally Spark assigns ports randomly for things like the driver and the block manager, but we need to configure Spark to bind to the correct ports, and also have the executors connect to the service we&amp;#8217;ve created instead of trying to connect back to the hostname of the driver. My service configuration is shown in &lt;a href=&quot;#sparkNetConf&quot;&gt;Spark Network Conf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sparkNetConf&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 14. Spark Network Conf&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;    &lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark.driver.port&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;2222&amp;quot;&lt;/span&gt;) &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Needs to match svc&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark.driver.blockManager.port&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;7777&amp;quot;&lt;/span&gt;)
    &lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark.driver.host&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;driver-service.jhub.svc.cluster.local&amp;quot;&lt;/span&gt;) &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Needs to match svc&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark.driver.bindAddress&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;0.0.0.0&amp;quot;&lt;/span&gt;) &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#  Otherwise tries to bind to svc IP, will fail&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition to that, you&amp;#8217;ll need to tell Spark which namespace it has permission to create executors in, shown in &lt;a href=&quot;#sparkNSConf&quot;&gt;Spark Namespace Conf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sparkNSConf&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Example 15. Spark Namespace Conf&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;    &lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark.kubernetes.namespace&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;spark&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While it&amp;#8217;s not essential, configuring an application name makes debugging much easier. You can do this with &lt;code&gt;.set(&quot;spark.app.name&quot;, &quot;PySparkHelloWorldInsideTheCluster&quot;)&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The process of adding a Spark notebook to your JupyterHub launcher is a little more involved than it is for typical notebooks because of the required permissions and network connections. Moving inside the cluster from outside of the cluster can offer many advantages, especially if your connection to the cluster goes over the internet. If you aren&amp;#8217;t familiar with Spark, there is a new version of &lt;a href=&quot;https://amzn.to/2WxB1I1&quot;&gt;&lt;em&gt;Learning Spark&lt;/em&gt;&lt;/a&gt; by my former co-workers (or you can buy the &lt;a href=&quot;https://amzn.to/2Ww3s98&quot;&gt;old one I co-wrote&lt;/a&gt;, but it&amp;#8217;s pretty out of date), along with Rachel &amp;amp; my &lt;a href=&quot;https://amzn.to/3paoE0L&quot;&gt;&lt;em&gt;High Performance Spark&lt;/em&gt;&lt;/a&gt;. Up next, I&amp;#8217;m planning on deploying Ray on the cluster, then jumping back to Dask and with the GitHub and BitCoin data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Having your Spark Notebook inside the same cluster as the executors can reduce network errors and improve uptime. Since these network issues can result in job failure, this is an important consideration. This post assumes that you&amp;#8217;ve already set up the foundation JupyterHub inside of Kubernetes deployment; the Dask-distributed notebook blog post covers that if you haven&amp;#8217;t.</summary></entry><entry><title type="html">Deploying Jupyter Lab/Notebook for Dask on ARM on Kubernetes</title><link href="https://scalingpythonml.com/2020/12/12/deploying-jupyter-lab-notebook-for-dask-on-arm-on-k8s.html" rel="alternate" type="text/html" title="Deploying Jupyter Lab/Notebook for Dask on ARM on Kubernetes" /><published>2020-12-12T00:00:00-08:00</published><updated>2020-12-12T00:00:00-08:00</updated><id>https://scalingpythonml.com/2020/12/12/deploying-jupyter-lab-notebook-for-dask-on-arm-on-k8s</id><content type="html" xml:base="https://scalingpythonml.com/2020/12/12/deploying-jupyter-lab-notebook-for-dask-on-arm-on-k8s.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this post, we are going to go through how to deploy Jupyter Lab on ARM on Kubernetes. We&amp;#8217;ll also build a container for use with Dask, but you can skip/customize this step to meet your own needs. In the &lt;a href=&quot;/2020/11/03/a-first-look-at-dask-on-arm-on-k8s.html&quot;&gt;previous post, I got Dask on ARM on Kubernetes working&lt;/a&gt;, while using remote access to allow the Jupyter notebook to run outside of the cluster. After running into a few issues from having the client code outside of the cluster, I decided it was worth the effort to set up Jupyter on ARM on K8s.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_rebuilding-the-jupyterhub-containers&quot;&gt;Rebuilding the JupyterHub Containers&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The default Jupyter containers are not yet cross-built for ARM. If your primary development machine is not an ARM machine, you&amp;#8217;ll want to set up Docker buildx for cross-building, and I&amp;#8217;ve got some instructions on how to do this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock warning&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Warning&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of Jupyter&amp;#8217;s containers uses cgo to build a small bootstrap program: this program will not build under QEMU. If you get an error building your containers check out &lt;a href=&quot;/2020/12/11/some-sharp-corners-with-docker-buildx.html&quot;&gt;my instructions on cross-building with real hosts.&lt;/a&gt; You can also cross-build without QEMU (discussed in the same post).&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;JupyterLab uses a special program called &lt;a href=&quot;https://pypi.org/project/chartpress/&quot;&gt;ChartPress&lt;/a&gt; to build it&amp;#8217;s images. This program&amp;#8217;s compose building capabilities are similar to Docker&amp;#8217;s but are Python focused. To make ChartPress use Docker buildx, you&amp;#8217;ll want to clone the repo &lt;code&gt;git clone &lt;a href=&quot;mailto:git@github.com&quot;&gt;git@github.com&lt;/a&gt;:jupyterhub/chartpress.git&lt;/code&gt; and replace the following line in chartpress.py&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;diff&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #A00000&quot;&gt;-    cmd = [&amp;#39;docker&amp;#39;, &amp;#39;build&amp;#39;, &amp;#39;-t&amp;#39;, image_spec, context_path]&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    cmd = [&amp;#39;docker&amp;#39;, &amp;#39;buildx&amp;#39;, &amp;#39;build&amp;#39;, &amp;#39;-t&amp;#39;, image_spec, context_path, &amp;quot;--platform&amp;quot;, &amp;quot;linux/arm64,linux/amd64&amp;quot;, &amp;quot;--push&amp;quot;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Then you can pip install your local version:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;pip install -e .&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that you have ChartPress set up to cross-build for ARM64 and AMD64, you can check out &lt;a href=&quot;https://github.com/jupyter/docker-stacks&quot;&gt;docker-stacks repo&lt;/a&gt; and make a few changes. First is the base notebook container targets a specific non-cross platform hash, so we&amp;#8217;ll change the &quot;FROM&quot;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;diff&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #A00000&quot;&gt;-ARG ROOT_CONTAINER=ubuntu:focal-20200925@sha256:2e70e9c81838224b5311970dbf7ed16802fbfe19e7a70b3cbfa3d7522aa285b4&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+#ARG ROOT_CONTAINER=ubuntu:focal-20200925@sha256:2e70e9c81838224b5311970dbf7ed16802fbfe19e7a70b3cbfa3d7522aa285b4&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+ARG ROOT_CONTAINER=ubuntu:focal&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Next, is that Miniconda doesn&amp;#8217;t have full ARM64 support, so you&amp;#8217;ll want to swap the Miniconda install to Miniforge:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;diff&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #A00000&quot;&gt;-RUN wget --quiet https://repo.continuum.io/miniconda/Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #A00000&quot;&gt;-    echo &amp;quot;${miniconda_checksum} *Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh&amp;quot; | md5sum -c - &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #A00000&quot;&gt;-    /bin/bash Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh -f -b -p $CONDA_DIR &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #A00000&quot;&gt;-    rm Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+RUN export arch=$(uname -m) &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    if [ &amp;quot;$arch&amp;quot; == &amp;quot;aarm64&amp;quot; ]; then \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+      arch=&amp;quot;arm64&amp;quot;; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    fi; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    wget --quiet https://github.com/conda-forge/miniforge/releases/download/4.8.5-1/Miniforge3-4.8.5-1-Linux-${arch}.sh -O miniforge.sh &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    chmod a+x miniforge.sh &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    ./miniforge.sh -f -b -p $CONDA_DIR &amp;amp;&amp;amp; \&lt;/span&gt;

&lt;span style=&quot;color: #00A000&quot;&gt;+    rm miniforge.sh &amp;amp;&amp;amp; \&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The docker-stacks notebooks are built with a Makefile so to build the base image, you&amp;#8217;ll execute &lt;code&gt;OWNER=holdenk make build/base-notebook&lt;/code&gt;, where you set &quot;OWNER&quot; to your dockerhub username.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition to the docker-stack images you&amp;#8217;ll want to rebuild the zero-to-jupyterhub-k8s and jconfigurable-http-proxy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With zero-to-jupyter-hub-k8s you&amp;#8217;ll also need to change &lt;code&gt;images/singleuser-sample/Dockerfile&lt;/code&gt; to use the docker-stack image you built (e.g. in mine I replaced &lt;code&gt;FROM jupyter/base-notebook:45bfe5a474fa&lt;/code&gt; with &lt;code&gt;FROM  holdenk/base-notebook:latest&lt;/code&gt;) . The py-spy package will also need to be removed from the images/hub/requirements.txt file since it is not cross-built (and it is optional anyway). zero-to-jupyterhub-k8s is built with &lt;code&gt;chartpress&lt;/code&gt;, so you will just build with a custom image prefix as in &lt;a href=&quot;#ex_chartpress_build&quot;&gt;[ex_chartpress_build]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ex_chartpress_build&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;chartpress  --image-prefix holdenk/jupyter-hub-magic --force-build&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With jconfigurable-http-proxy no changes are necessary to the project it&amp;#8217;s self, and you can directly run &lt;code&gt;docker buildx build -t holdenk/jconfigurable-http-proxy:0.0.1 .  --platform linux/arm64,linux/amd64 --push&lt;/code&gt;. Note this is a different build command as the proxy project does not use chartpress.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_configuring-the-container-images&quot;&gt;Configuring the container images&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that you&amp;#8217;ve built the container images, we need to configure our helm chart to use them. When you run &lt;code&gt;chartpress&lt;/code&gt; inside of the zero-to-jupyterhub-k8s repo, it updates the jupyterhub values for the helm chart. You can either use this new chart by following the helm instruction on using a &lt;a href=&quot;https://v2.helm.sh/docs/chart_repository/&quot;&gt;chart repository&lt;/a&gt; (e.g. &lt;code&gt;helm install    $RELEASE ~/repos/scalingpythonml/scratch/zero-to-jupyterhub-k8s/jupyterhub   --namespace $NAMESPACE   --create-namespace       --values config.yaml&lt;/code&gt;) or you can use the existing published helm chart and override the images.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To install with the existing published chart you can run &lt;a href=&quot;#install_existing&quot;&gt;[install_existing]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;install_existing&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
helm repo update&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To override the images, you&amp;#8217;ll need to specify the images in your configuration to helm when your doing your install later as in &lt;a href=&quot;#img-config&quot;&gt;[img-config]&lt;/a&gt;. I put this in a file called &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;img-config&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hub&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magichub
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;proxy&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretSync&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicsecret-sync
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# This one needs to be override either way.&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;chp&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jconfigurable-http-proxy
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.0.1&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;singleuser&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;networkTools&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicnetwork-tools
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicsingleuser-sample
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;prePuller&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hook&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicimage-awaiter
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ll keep building on the above configuration, since we need to do more than just override the images.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_setting-up-a-ssl-certificate&quot;&gt;Setting up a SSL Certificate&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jupyter expects an SSL certificate for its endpoint. If you don&amp;#8217;t have cert manager installed, the guide at &lt;a href=&quot;https://opensource.com/article/20/3/ssl-letsencrypt-k3s&quot;&gt;&lt;a href=&quot;https://opensource.com/article/20/3/ssl-letsencrypt-k3s&quot; class=&quot;bare&quot;&gt;https://opensource.com/article/20/3/ssl-letsencrypt-k3s&lt;/a&gt; shows how to configure SSL using Let&amp;#8217;s Encrypt&lt;/a&gt;. If you don&amp;#8217;t have a publicly accessible IP and domain, you&amp;#8217;ll need to use an alternative provider. Once you have cert-manager installed it&amp;#8217;s time to request the certificate. The YAML for my certificate request for holdenkarau.mooo.com is shown in &lt;a href=&quot;#cert-req&quot;&gt;[cert-req]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;cert-req&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;apiVersion&lt;/span&gt;: cert-manager.io/v1alpha2
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kind&lt;/span&gt;: Certificate
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;metadata&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: k3s-mooo
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;namespace&lt;/span&gt;: jhub
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;spec&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretName&lt;/span&gt;: k3s-mooo-tls
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;issuerRef&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: letsencrypt-prod
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kind&lt;/span&gt;: ClusterIssuer
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;commonName&lt;/span&gt;: holdenkarau.mooo.com
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;dnsNames&lt;/span&gt;:
  - holdenkarau.mooo.com&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once you make your certificate request you can apply with &lt;code&gt;kubectl apply -f le-prod-cert.yaml&lt;/code&gt;, and monitor it with &lt;code&gt;kubectl get certificates -n jhub -w -o yaml&lt;/code&gt;. If your certificate does not become &quot;Ready&quot;, you should check out the &lt;a href=&quot;https://cert-manager.io/docs/faq/acme/&quot;&gt;cert-manager debugging guide&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that you&amp;#8217;ve got your SSl certificate stored as a secret in your cluster, you&amp;#8217;ll need configure your JupyterHub ingress to use it by adding &lt;a href=&quot;#ingres-config&quot;&gt;[ingres-config]&lt;/a&gt; to your &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ingress-config&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ingress&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;enabled&lt;/span&gt;: true
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hosts&lt;/span&gt;:
    - holdenkarau.mooo.com
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tls&lt;/span&gt;:
   - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hosts&lt;/span&gt;:
      - holdenkarau.mooo.com
     &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretName&lt;/span&gt;: k3s-mooo-tls&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_making-jupyter-work-without-a-second-public-ip&quot;&gt;Making Jupyter work without a second public IP&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since my home only has one public IP address, I changed the service type from LodeBalancer to NodePort, since I did not have a spare public IP to assign to Jupyter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;proxy&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;service&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;type&lt;/span&gt;: NodePort
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretToken&lt;/span&gt;: DIFFERENTSECRET&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With this change the service deployed successfully and Traefik (installed in K3s by default) was able to route the requests.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_setting-up-authentication&quot;&gt;Setting up Authentication&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I was unable to get the JupyterHub GitHub plugin working, but it looks like there is
an &lt;a href=&quot;https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues/1871&quot;&gt;outstanding issue to refactor the auth configuration,&lt;/a&gt;
so for now I just hard coded what is known as &quot;dummy&quot; authentication. I recommend using a different kind of authentication as soon as the refactoring is complete.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;auth&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;type&lt;/span&gt;: dummy
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;dummy&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;password&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;mypassword&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;whitelist&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;users&lt;/span&gt;:
      - user1
      - user2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_installing-jupyterhub-with-helm&quot;&gt;Installing JupyterHub with Helm&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now you can install this with Helm:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;RELEASE&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;jhub

&lt;span style=&quot;color: #19177C&quot;&gt;NAMESPACE&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;jhub

helm install    &lt;span style=&quot;color: #19177C&quot;&gt;$RELEASE&lt;/span&gt; jupyterhub/jupyterhub   --namespace &lt;span style=&quot;color: #19177C&quot;&gt;$NAMESPACE&lt;/span&gt;   --create-namespace   --version&lt;span style=&quot;color: #666666&quot;&gt;=0&lt;/span&gt;.10.2     --values config.yaml&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And now you&amp;#8217;re ready to rock and roll with JupyterHub! However, part of the config is still commented out; that&amp;#8217;s because we have not yet built the single user Dask Jupyter Docker container. If you aren&amp;#8217;t using Dask, this can be your stopping point.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_adding-dask-support&quot;&gt;Adding Dask Support&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Adding Dask Support involves configuring permissions to make sure the notebook can create executors, building an image to work with your JupyterHub launcher, and adding the image to as a profile to your launcher.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_permissions&quot;&gt;Permissions&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The default service account used will probably not have the right permissions to launch dask-distributed workers.
To start with create a specification for the what permission your notebook is going to need, I called my &lt;code&gt;setup.yaml&lt;/code&gt; (not very creative I know) as in &lt;a href=&quot;#ex-perm-yaml&quot;&gt;[ex-perm-yaml]&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ex-perm-yaml&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kind&lt;/span&gt;: Role
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;apiVersion&lt;/span&gt;: rbac.authorization.k8s.io/v1beta1
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;metadata&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: daskKubernetes
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;namespace&lt;/span&gt;: dask
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;rules&lt;/span&gt;:
- &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;apiGroups&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;  &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# indicates the core API group&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;resources&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;pods&amp;quot;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;verbs&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;get&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;list&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;watch&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;create&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;delete&amp;quot;&lt;/span&gt;
- &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;apiGroups&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;  &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# indicates the core API group&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;resources&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;pods/log&amp;quot;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;verbs&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;get&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;list&amp;quot;&lt;/span&gt;
- &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;apiGroups&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# indicates the core API group&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;resources&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;services&amp;quot;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;verbs&lt;/span&gt;:
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;get&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;list&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;watch&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;create&amp;quot;&lt;/span&gt;
  - &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;delete&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that you&amp;#8217;ve specified the permissions you can go ahead and create the accounts, namespaces, and bindings to wire everything together as in &lt;a href=&quot;#ex-setup-namespace&quot;&gt;[ex-setup-namespace]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;ex-setup-namespace&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;kubectl create namespace dask
kubectl create serviceaccount dask --namespace dask
kubectl apply -f setup.yaml
kubectl create rolebinding dask-sa-binding --namespace dask --role&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;daskKubernetes --user&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;dask:dask&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_building-container-images&quot;&gt;Building container images&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/dask/dask-docker&quot;&gt;dask-docker&lt;/a&gt; project contains a notebook container file; however, it is not designed for use with JupyterHub&amp;#8217;s launcher. The first change needed is commenting out the auto start in &lt;code&gt;notebook/prepare.sh&lt;/code&gt;. The other required change is swapping the Dockerfile with your cross-built &amp;#8201;&amp;#8212;&amp;#8201;single-user-sample. I updated mine to also install some helpful libraries as in &lt;a href=&quot;#my_dask_nb_dockerfile&quot;&gt;[my_dask_nb_dockerfile]&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;my_dask_nb_dockerfile&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;dockerfile&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;FROM&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;  holdenk/jupyter-hub-magicsingleuser-sample:0.10.2&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; root&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; apt-get update &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -yq graphviz git build-essential &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get clean &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf /var/lib/apt/lists/*

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; touch /hello_holden

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; $NB_USER&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; conda install -c conda-forge --yes mamba
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;python&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.8.6
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;aiohttp&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.7.1 &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install &lt;span style=&quot;color: #19177C&quot;&gt;aiohttp&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.7.1 &lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; mamba install --yes &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    python-blosc &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    cytoolz &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #19177C&quot;&gt;dask&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==2&lt;/span&gt;.30.0 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    dask-core&lt;span style=&quot;color: #666666&quot;&gt;==2&lt;/span&gt;.30.0 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    lz4 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #19177C&quot;&gt;numpy&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==1&lt;/span&gt;.19.2 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    ipywidgets &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    python-graphviz &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mamba install --yes s3fs gcsfs dropboxdrivefs requests dropbox paramiko adlfs pygit2 pyarrow &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    mamba install --yes bokeh numba llvmlite
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes fastparquet &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install fastparquet&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes jupyter-server-proxy &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install jupyter-server-proxy&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes dask-labextension&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.0.0 &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install dask-labextension&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.0.0&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; jupyter labextension install @jupyter-widgets/jupyterlab-manager dask-labextension@3.0.0 @jupyterlab/server-proxy &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; jupyter serverextension &lt;span style=&quot;color: #008000&quot;&gt;enable&lt;/span&gt; dask-labextension@3.0.0 @jupyterlab/server-proxy &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; pip install dask-kubernetes&lt;span style=&quot;color: #666666&quot;&gt;==0&lt;/span&gt;.11.0 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; jupyter lab clean &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; jlpm cache clean &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; npm cache clean --force &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/ -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.a&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/ -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.pyc&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/ -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.js.map&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/lib/python*/site-packages/bokeh/server/static -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.js&amp;#39;&lt;/span&gt; -not -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.min.js&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;no bokeh static files to cleanup&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf /opt/conda/pkgs

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;USER&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; root&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Create the /opt/app directory, and assert that Jupyter&amp;#39;s NB_UID/NB_GID values&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# haven&amp;#39;t changed.&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; mkdir /opt/app &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;if&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$NB_UID&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; !&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;1000&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$NB_GID&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; !&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;100&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;then&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;Jupyter&amp;#39;s NB_UID/NB_GID changed, need to update the Dockerfile&amp;quot;&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #008000&quot;&gt;exit&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;1&lt;/span&gt;; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;fi&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Copy over the example as NB_USER. Unfortuantely we can&amp;#39;t use $NB_UID/$NB_GID&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# in the `--chown` statement, so we need to hardcode these values.&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; --chown&lt;span style=&quot;color: #666666&quot;&gt;=1000&lt;/span&gt;:100 examples/ /home/&lt;span style=&quot;color: #19177C&quot;&gt;$NB_USER&lt;/span&gt;/examples
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; prepare.sh /usr/bin/prepare.sh

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENTRYPOINT&lt;/span&gt; [&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;tini&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;--&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;/usr/bin/prepare.sh&amp;quot;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As before you can build this with the standard &lt;code&gt;docker buildx&lt;/code&gt; commands.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_configuring-your-jupyter&quot;&gt;Configuring your Jupyter&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To enable Dask with Jupyter you&amp;#8217;ll need to update your configuration to both specify the service account and add a profile for for the notebook container you&amp;#8217;ve created. In my situation this looks like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once your done with your config changes,  you need to update your install with &lt;code&gt;helm upgrade --cleanup-on-fail   --install $RELEASE jupyterhub/jupyterhub   --namespace $NAMESPACE   --create-namespace   --version=0.10.2   --values config.yaml&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All in all my confiugration file looks something like &lt;a href=&quot;#my-total-config&quot;&gt;[my-total-config]&lt;/a&gt; (except with diffferent secrets). Your config file will look a bit different depending on the choices you made while running through this config.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;my-total-config&quot; class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hub&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magichub
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;proxy&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;service&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;type&lt;/span&gt;: NodePort
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretToken&lt;/span&gt;: DIFFERENTSECRET
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretSync&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicsecret-sync
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;chp&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jconfigurable-http-proxy
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.0.1&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ingress&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;enabled&lt;/span&gt;: true
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hosts&lt;/span&gt;:
    - holdenkarau.mooo.com
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tls&lt;/span&gt;:
   - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hosts&lt;/span&gt;:
      - holdenkarau.mooo.com
     &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;secretName&lt;/span&gt;: k3s-mooo-tls
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;singleuser&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;serviceAccountName&lt;/span&gt;: dask
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;networkTools&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicnetwork-tools
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicsingleuser-sample
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;profileList&lt;/span&gt;:
    - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;display_name&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;Minimal&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;environment&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;description&lt;/span&gt;: &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;&amp;quot;To avoid too much bells and whistles&lt;/span&gt;: Python.&amp;quot;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;default&lt;/span&gt;: true
    - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;display_name&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;Dask&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;container&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;description&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;If&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;you&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;want&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;to&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;run&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;dask&amp;quot;&lt;/span&gt;
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kubespawner_override&lt;/span&gt;:
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;: holdenk/dask-notebook:v0.9.4b
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;prePuller&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;hook&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: holdenk/jupyter-hub-magicimage-awaiter
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;tag&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;0.10.2&amp;#39;&lt;/span&gt;
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Do something better here! It&amp;#39;s being reworked though - https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues/1871&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;auth&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;type&lt;/span&gt;: dummy
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;dummy&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;password&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;mypassword&amp;#39;&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;whitelist&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;users&lt;/span&gt;:
      - user1
      - user2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now you&amp;#8217;re ready to rock-and-role with more stable Dask jobs, that can survive when your notebook goes to sleep or your home internet connection goes out between you and your cluster. The next blog post will explore how this is a bit more involved for building a JupyterHub launcher container for a Spark notebook.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">In this post, we are going to go through how to deploy Jupyter Lab on ARM on Kubernetes. We&amp;#8217;ll also build a container for use with Dask, but you can skip/customize this step to meet your own needs. In the previous post, I got Dask on ARM on Kubernetes working, while using remote access to allow the Jupyter notebook to run outside of the cluster. After running into a few issues from having the client code outside of the cluster, I decided it was worth the effort to set up Jupyter on ARM on K8s.</summary></entry><entry><title type="html">Some sharp corners with docker buildx (especially with qemu)</title><link href="https://scalingpythonml.com/2020/12/11/some-sharp-corners-with-docker-buildx.html" rel="alternate" type="text/html" title="Some sharp corners with docker buildx (especially with qemu)" /><published>2020-12-11T00:00:00-08:00</published><updated>2020-12-11T00:00:00-08:00</updated><id>https://scalingpythonml.com/2020/12/11/some-sharp-corners-with-docker-buildx</id><content type="html" xml:base="https://scalingpythonml.com/2020/12/11/some-sharp-corners-with-docker-buildx.html">&lt;p&gt;Have you been trying out Dockers wonderful new buildx with QEMU, but are getting an unexpected exec user process caused: exec format error or strange segfaults on ARM? If so, this short and sweet blog post is for you. I want to be clear: I think buildx with qemu is amazing, but there are some sharp edges to keep your eyes out on.&lt;/p&gt;

&lt;h2 id=&quot;cross-building-sharp-edges&quot;&gt;Cross building sharp edges&lt;/h2&gt;

&lt;p&gt;First, there are some issues when using cgo (and less often gcc) with QEMU which can sometimes cause segfaults. For me this showed up as qemu: uncaught target signal 4 (Illegal instruction) - core dumped. Future versions of cgo, gcc or QEMU may work around these issues, but if you find yourself getting errors while building what seems like a trivial example, theres a good chance youve run into this. Ive dealt with this problem by using an actual ARM machine for my cross-building.&lt;/p&gt;

&lt;p&gt;The other sharp edge is that you can accidentally build a native architecture Docker image labeled as the cross-architecture image, and only find out at runtime. This can happen when the FROM label in your Dockerfile specifies a specific hash. In this case, the easiest thing to do is specify a version tag instead. While it wont fix the problem, using an actual target architecture machine for your building will let you catch this earlier on.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;Dont despair, though, instead of QEMU, we can use remote contexts. First, get a machine based on your target architecture. If you dont have one handy, some cloud providers offer a variety of architectures. Then, if your machine doesnt already have Docker on it, install Docker. Once youve set up docker on the remote machine, you can create a docker context for it. In my case, I have ssh access (with keys) as the root user to a jetson nano at 192.168.3.125, so I create my context as:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker context create jetson-nano-ctx &lt;span class=&quot;nt&quot;&gt;--docker&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ssh://root@192.168.3.125
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once you have a remote context, you can use it in a build instance. If you have QEMU locally, as I do, its important that the remote context is set to be used, since otherwise, we will still try to build with emulation.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker buildx create &lt;span class=&quot;nt&quot;&gt;--use&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; mybuild-combined-builder jetson-nano-ctx 

docker buildx create &lt;span class=&quot;nt&quot;&gt;--append&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; mybuild-combined-builder
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another random sharp edge that Ive run into with Docker buildx is a lot of transient issues seem to go away when I rerun the same command (e.g., failed to solve: rpc error: code = Unknown desc = failed commit on ref). I imagine this might be due to a race condition because when I rerun it, Docker buildx uses caching  but thats just a hunch.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Another option, especially for GO, is to do your build on your source arch targeting your target arch. There is a Docker blog post &lt;a href=&quot;https://www.docker.com/blog/containerize-your-go-developer-environment-part-1/&quot;&gt;on that approach here.&lt;/a&gt; Cross-building C libraries is also an option, but more complicated.&lt;/p&gt;

&lt;p&gt;Now youre ready to go off to the races and build with your remote machine. Dont worry you can change your build instance back to your local context (use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker buildx ls&lt;/code&gt; to see your contexts). Happy porting, everyone!&lt;/p&gt;

&lt;p&gt;Have you run into additional sharp corners with QEMU &amp;amp; buildx? Let me know and Ill update this post :)&lt;/p&gt;</content><author><name></name></author><summary type="html">Have you been trying out Dockers wonderful new buildx with QEMU, but are getting an unexpected exec user process caused: exec format error or strange segfaults on ARM? If so, this short and sweet blog post is for you. I want to be clear: I think buildx with qemu is amazing, but there are some sharp edges to keep your eyes out on.</summary></entry><entry><title type="html">A First Look at Dask on ARM on K8s</title><link href="https://scalingpythonml.com/2020/11/03/a-first-look-at-dask-on-arm-on-k8s.html" rel="alternate" type="text/html" title="A First Look at Dask on ARM on K8s" /><published>2020-11-03T00:00:00-08:00</published><updated>2020-11-03T00:00:00-08:00</updated><id>https://scalingpythonml.com/2020/11/03/a-first-look-at-dask-on-arm-on-k8s</id><content type="html" xml:base="https://scalingpythonml.com/2020/11/03/a-first-look-at-dask-on-arm-on-k8s.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After getting the cluster set up in the previous post, it was time to finally play with Dask on the cluster. Thankfully, there are &lt;a href=&quot;https://github.com/dask/dask-kubernetes&quot;&gt;dask-kubernetes&lt;/a&gt; and &lt;a href=&quot;https://github.com/dask/dask-docker&quot;&gt;dask-docker&lt;/a&gt; projects that provide the framework to do this. Since I&amp;#8217;m still new to Dask, I decided to start off by using Dask from a local notebook (in retrospect maybe not the best choice).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_getting-dask-on-arm-in-docker&quot;&gt;Getting Dask on ARM in Docker&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The dask-docker project gives us a good starting point for building a container for Dask, but the project&amp;#8217;s containers are only built for amd64. I started off by trying to rebuild the containers without any modifications, but it turned out there were a few issues that I needed to address. The first is that the regular conda docker image is also only built for amd64. Secondly, some of the packages that the Dask container uses are also not yet cross-built. While these problems will likely go away over the coming year, for the time being, I solved these issues by making a multi-platform condaforge docker container, asking folks to rebuild packages, and, when the packages did not get rebuilt, installing from source.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To do this I created a new Dockerfile for replacing miniconda base with miniforge:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;dockerfile&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;FROM&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt; debian:buster-slim&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;LANG&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;C.UTF-8 &lt;span style=&quot;color: #19177C&quot;&gt;LC_ALL&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;C.UTF-8
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; PATH /opt/conda/bin:&lt;span style=&quot;color: #19177C&quot;&gt;$PATH&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; apt-get update --fix-missing &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get install -y wget bzip2 ca-certificates libglib2.0-0 libxext6 libsm6 libxrender1 git mercurial subversion &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get clean

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; setup.sh /setup.sh
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; /setup.sh
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;CMD&lt;/span&gt; [ &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;/bin/bash&amp;quot;&lt;/span&gt; ]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Most of the logic lives in this setup script:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;sh&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span style=&quot;color: #008000&quot;&gt;set&lt;/span&gt; -ex
&lt;span style=&quot;color: #008000&quot;&gt;export&lt;/span&gt; &lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;$(&lt;/span&gt;uname -m&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;)&lt;/span&gt;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;if&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;[&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;$arch&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;==&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;aarm64&amp;quot;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;]&lt;/span&gt;; &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;then&lt;/span&gt;
  &lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;arm64&amp;quot;&lt;/span&gt;;
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;fi&lt;/span&gt;
wget --quiet https://github.com/conda-forge/miniforge/releases/download/4.8.5-1/Miniforge3-4.8.5-1-Linux-&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;${&lt;/span&gt;&lt;span style=&quot;color: #19177C&quot;&gt;arch&lt;/span&gt;&lt;span style=&quot;color: #BB6688; font-weight: bold&quot;&gt;}&lt;/span&gt;.sh -O ~/miniforge.sh
chmod a+x ~/miniforge.sh
~/miniforge.sh -b -p /opt/conda
/opt/conda/bin/conda clean -tipsy
ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh
&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;. /opt/conda/etc/profile.d/conda.sh&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bashrc
&lt;span style=&quot;color: #008000&quot;&gt;echo&lt;/span&gt; &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;conda activate base&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bashrc
&lt;span style=&quot;color: #008000&quot;&gt;source&lt;/span&gt; ~/.bashrc
find /opt/conda/ -follow -type f -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.a&amp;#39;&lt;/span&gt; -delete
find /opt/conda/ -follow -type f -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.js.map&amp;#39;&lt;/span&gt; -delete
/opt/conda/bin/conda clean -afy
/opt/conda/bin/conda install --yes nomkl cytoolz cmake tini
/opt/conda/bin/conda init bash
/opt/conda/bin/conda install --yes mamba&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I chose to install mamba, a fast C++ reimplementation of conda, and use this to install the rest of the packages. I did this since debugging the package conflicts with the regular conda program was resulting in confusing error messages, and mamba can have clearer error messages. I created a new version of the &quot;base&quot; Dockerfile, from dask-docker, which installed the packages with mamba and pip when not available from conda.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;dockerfile&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;FROM&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;  holdenk/miniforge:v0.3&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;SHELL&lt;/span&gt; [&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;/bin/bash&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;-c&amp;quot;&lt;/span&gt;]

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENV&lt;/span&gt; PATH /opt/conda/bin:&lt;span style=&quot;color: #19177C&quot;&gt;$PATH&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; apt-get update --force-yes  -y --fix-missing &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get install --force-yes  -y wget bzip2 ca-certificates libglib2.0-0 libxext6 libsm6 libxrender1 git mercurial subversion &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get install --force-yes -y build-essential cmake libcurl4 libcurl4-openssl-dev libblosc-dev libblosc1 python3-blosc python3-dev &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get upgrade --force-yes -y &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    apt-get clean

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;python&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.8.6 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mamba install --yes &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    cytoolz &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #19177C&quot;&gt;dask&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==2&lt;/span&gt;.30.0 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    dask-core&lt;span style=&quot;color: #666666&quot;&gt;==2&lt;/span&gt;.30.0 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    lz4 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #19177C&quot;&gt;numpy&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==1&lt;/span&gt;.19.2 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    pandas &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    tini &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    scikit-build &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    python-blosc&lt;span style=&quot;color: #666666&quot;&gt;=1&lt;/span&gt;.9.2 &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    pyzmq &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mamba install --yes s3fs gcsfs dropboxdrivefs requests dropbox paramiko adlfs pygit2 pyarrow&lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mamba install --yes bokeh &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes &lt;span style=&quot;color: #19177C&quot;&gt;aiohttp&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.7.1 &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install &lt;span style=&quot;color: #19177C&quot;&gt;aiohttp&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;==3&lt;/span&gt;.7.1 &lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes jupyter-server-proxy &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install jupyter-server-proxy&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes llvmlite numba &lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;(&lt;/span&gt;mamba install --yes fastparquet &lt;span style=&quot;color: #666666&quot;&gt;||&lt;/span&gt; pip install fastparquet&lt;span style=&quot;color: #666666&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/ -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.a&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/ -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.pyc&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/ -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.js.map&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; find /opt/conda/lib/python*/site-packages/bokeh/server/static -type f,l -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.js&amp;#39;&lt;/span&gt; -not -name &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;*.min.js&amp;#39;&lt;/span&gt; -delete &lt;span style=&quot;color: #BB6622; font-weight: bold&quot;&gt;\&lt;/span&gt;
    &lt;span style=&quot;color: #666666&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf /opt/conda/pkgs

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# pyzmq is installed explicitly so we don&amp;#39;t have to build it from src since jupyter-server-proxy needs it, but jupyter-server-proxy won&amp;#39;t install from conda directly&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;COPY&lt;/span&gt; prepare.sh /usr/bin/prepare.sh

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;RUN&lt;/span&gt; mkdir /opt/app

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;ENTRYPOINT&lt;/span&gt; [&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;tini&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;-g&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;--&amp;quot;&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;/usr/bin/prepare.sh&amp;quot;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One interesting thing I noticed while exploring this is the link::https://github.com/dask/dask-docker/blob/master/base/prepare.sh[prepare.sh script] that is used as the entry point for the container. This script checks a few different environment variables that, when present, are used to install additional packages (Python or system) at container startup. While normally putting all of the packages into a container is best (since installations can be flaky and slow), this does allow for faster experimentation. At first glance, it seems like this still requires a Dask cluster restart to add a new package, but I&amp;#8217;m going to do more exploring here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_getting-dask-on-kube&quot;&gt;Getting Dask on Kube&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With the containers built, the next step was trying to get them running on Kubernetes. I first tried the helm installation, but I wasn&amp;#8217;t super sure how to configure it to use my new custom containers and the documentation also contained warnings indicating that Dask with helm did not play well with dynamic scaling. Since I&amp;#8217;m really interested in exploring how the different systems support dynamic scaling, I decided to install the dask-kubernetes project. With dask-kubernetes, I can create a cluster by running:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;cluster &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; KubeCluster&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;from_yaml(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;worker-spec.yaml&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As I was setting this up, I realized it was creating resources in the default namespace, which made keeping track of everything difficult. So I created a namespace, service account, and role binding so that I could better keep track of (and clean up) everything:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;kubectl create namespace dask
kubectl create serviceaccount dask &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;namespace dask
kubectl &lt;span style=&quot;color: #008000&quot;&gt;apply&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;f setup&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;yaml
kubectl create rolebinding dask&lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;sa&lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;binding &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;namespace dask &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;role&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;daskKubernetes &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;user&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;dask:dask&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To use this, I rewrote added another parameter to cluster creation and updated the yaml:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;cluster &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; KubeCluster&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;from_yaml(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;worker-spec.yaml&amp;#39;&lt;/span&gt;, namespace&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;dask&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The from_yaml is important, as it lets me specify specific containers and resource requests (which will be useful when working with GPUs). I modified the standard worker-spec to use the namespace and service account I created.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# worker-spec.yml&lt;/span&gt;

&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;kind&lt;/span&gt;: Pod
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;metadata&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;namespace&lt;/span&gt;: dask
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;labels&lt;/span&gt;:
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;foo&lt;/span&gt;: bar5
&lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;spec&lt;/span&gt;:
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;restartPolicy&lt;/span&gt;: Never
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Added by holden&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;serviceAccountName&lt;/span&gt;: dask
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;automountServiceAccountToken&lt;/span&gt;: true
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# End added by Holden&lt;/span&gt;
  &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;containers&lt;/span&gt;:
&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Configure for dual arch&lt;/span&gt;
  - &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;image&lt;/span&gt;: holdenk/dask-base:v0.9.1
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;imagePullPolicy&lt;/span&gt;: IfNotPresent
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;args&lt;/span&gt;: [&lt;span style=&quot;color: #19177C&quot;&gt;dask-worker&lt;/span&gt;, &lt;span style=&quot;color: #19177C&quot;&gt;--nthreads&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;2&amp;#39;&lt;/span&gt;, &lt;span style=&quot;color: #19177C&quot;&gt;--no-dashboard&lt;/span&gt;, &lt;span style=&quot;color: #19177C&quot;&gt;--memory-limit&lt;/span&gt;, &lt;span style=&quot;color: #19177C&quot;&gt;6GB&lt;/span&gt;, &lt;span style=&quot;color: #19177C&quot;&gt;--death-timeout&lt;/span&gt;, &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;60&amp;#39;&lt;/span&gt;]
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;name&lt;/span&gt;: dask
    &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#env:&lt;/span&gt;
    &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#  - name: EXTRA_PIP_PACKAGES&lt;/span&gt;
    &lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;#    value: git+https://github.com/dask/distributed&lt;/span&gt;
    &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;resources&lt;/span&gt;:
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;limits&lt;/span&gt;:
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;cpu&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;2&amp;quot;&lt;/span&gt;
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;memory&lt;/span&gt;: 8G
      &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;requests&lt;/span&gt;:
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;cpu&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;2&amp;quot;&lt;/span&gt;
        &lt;span style=&quot;color: #008000; font-weight: bold&quot;&gt;memory&lt;/span&gt;: 8G&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While this would work if I was &lt;em&gt;inside&lt;/em&gt; the Kubernetes cluster I wanted to start with an experimental notebook outside the cluster. This required some changes, and in retrospect is not where I should have started.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_dask-in-kube-with-notebook-access&quot;&gt;Dask in Kube with Notebook access&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are two primary considerations when setting up Dask for notebook access on Kube. The first is where you want your notebook to run, inside the Kubernetes cluster or outside (e.g. on your machine). The second consideration is if you want the Dask scheduler to run alongside your notebook, or in a separate container inside of Kube.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first configuration I tried was having a notebook on my local machine. At first, I could not get it working because the scheduler was running on my local machine and could not talk to the worker pods it spun up. That&amp;#8217;s why, unless you&amp;#8217;re using host networking, I recommend having the scheduler run inside the cluster. Doing this involves adding a &quot;deploy_mode&quot; keyword to your KubeCluster invocation and asking Dask to create a service for your notebook to talk to the scheduler.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;

&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# In[2]:&lt;/span&gt;


&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# Specify a remote deployment using a load blanacer, necessary for communication with notebook from cluster&lt;/span&gt;
dask&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;config&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;set({&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;kubernetes.scheduler-service-type&amp;quot;&lt;/span&gt;: &lt;span style=&quot;color: #BA2121&quot;&gt;&amp;quot;LoadBalancer&amp;quot;&lt;/span&gt;})


&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# In[4]:&lt;/span&gt;


cluster &lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt; KubeCluster&lt;span style=&quot;color: #666666&quot;&gt;.&lt;/span&gt;from_yaml(&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;worker-spec.yaml&amp;#39;&lt;/span&gt;, namespace&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;dask&amp;#39;&lt;/span&gt;, deploy_mode&lt;span style=&quot;color: #666666&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;color: #BA2121&quot;&gt;&amp;#39;remote&amp;#39;&lt;/span&gt;)


&lt;span style=&quot;color: #408080; font-style: italic&quot;&gt;# In[ ]:&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Running your notebook on a local machine &lt;em&gt;may&lt;/em&gt; make getting started faster, but it comes with some downsides. It&amp;#8217;s important that you keep your client&amp;#8217;s python environment in sync with the worker/base containers. For me setting up my conda env, I ended up having to run:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot; style=&quot;background: #f8f8f8;&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;sudo &lt;span style=&quot;color: #666666&quot;&gt;/&lt;/span&gt;opt&lt;span style=&quot;color: #666666&quot;&gt;/&lt;/span&gt;conda&lt;span style=&quot;color: #666666&quot;&gt;/&lt;/span&gt;&lt;span style=&quot;color: #008000&quot;&gt;bin&lt;/span&gt;&lt;span style=&quot;color: #666666&quot;&gt;/&lt;/span&gt;conda install &lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;c conda&lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;forge &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;&lt;span style=&quot;color: #008000&quot;&gt;all&lt;/span&gt; &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;yes mamba
mamba install &lt;span style=&quot;color: #666666&quot;&gt;--&lt;/span&gt;yes python&lt;span style=&quot;color: #666666&quot;&gt;==3.8.6&lt;/span&gt; cytoolz dask&lt;span style=&quot;color: #666666&quot;&gt;==2.30.0&lt;/span&gt; dask&lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;core&lt;span style=&quot;color: #666666&quot;&gt;==2.30.0&lt;/span&gt; lz4 numpy&lt;span style=&quot;color: #666666&quot;&gt;==1.19.2&lt;/span&gt; pandas tini \
      scikit&lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;build python&lt;span style=&quot;color: #666666&quot;&gt;-&lt;/span&gt;blosc&lt;span style=&quot;color: #666666&quot;&gt;=1.9.2&lt;/span&gt; pyzmq s3fs gcsfs dropboxdrivefs requests dropbox paramiko adlfs \
      pygit2 pyarrow bokeh aiottp&lt;span style=&quot;color: #666666&quot;&gt;==3.7.1&lt;/span&gt; llvmlite numba fastparquet&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another big issue you&amp;#8217;ll likely run into is that transient network errors between your notebook and the cluster can result in non-recoverable errors. This has happened to me even with networking all inside my house, so I can imagine that it would be even more common with a VPN or a cloud provider network involved.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The final challenge that I ran into was with I/O. Some code will run in the workers and some will run on the client, and if your workers and client have a different network view or if there are resources that are only available inside the cluster (for me MinIO), the error messages can be confusing &lt;sup class=&quot;footnote&quot;&gt;[&lt;a id=&quot;_footnoteref_1&quot; class=&quot;footnote&quot; href=&quot;#_footnotedef_1&quot; title=&quot;View footnote.&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Note: you don&amp;#8217;t have to use Dask with Kubernetes, or even a cluster. If you don&amp;#8217;t have a cluster, or have a problem where a cluster might not be the best solution, Dask also supports other execution environments like multithreading and GPU acceleration. I&amp;#8217;m personally excited to see how the GPU acceleration can be used together with Kubernetes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_the-different-apis&quot;&gt;The different APIs&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dask exposes a few different APIs for distributed programming at different levels of abstraction. Dask&amp;#8217;s &quot;core&quot; building block is the delayed API, on top of which collections and DataFrame support is built. The delayed API is notably a lower level API than Spark&amp;#8217;s low level public APIs&amp;#8201;&amp;#8212;&amp;#8201;and I&amp;#8217;m super interested to see what kind of things it enables us to do.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dask has three different types of distributed collection APIs: Bag, DataFrame, and Array. These distributed collections map relatively nicely to common Python concepts, and the DataFrame API is especially familiar.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Almost &lt;sup class=&quot;footnote&quot;&gt;[&lt;a id=&quot;_footnoteref_2&quot; class=&quot;footnote&quot; href=&quot;#_footnotedef_2&quot; title=&quot;View footnote.&quot;&gt;2&lt;/a&gt;]&lt;/sup&gt; separate from the delayed and collections APIs, Dask also has an (experimental) Actor API. I&amp;#8217;m curious to see how this API continues to be developed and used. I&amp;#8217;d really like to see if I can use it as a parameter server.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To verify my cluster was properly set up I did a quick run through the tutorials for the different APIs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_next-steps&quot;&gt;Next Steps&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now that I&amp;#8217;ve got Dask on Kube running on my cluster I want to do some cleanup and then explore more about how Dask handles dataframes, partitioning/distributing data/tasks, auto scaling, and GPU acceleration. If you&amp;#8217;ve got any suggestions for things you&amp;#8217;d like me to try out, do please get in touch :)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;footnotes&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;footnote&quot; id=&quot;_footnotedef_1&quot;&gt;
&lt;a href=&quot;#_footnoteref_1&quot;&gt;1&lt;/a&gt;. I worked around this by setting up port-forwarding so that the network environment was the same between my local machine and the cluster. You could also expose the internal-only resources through a service and have internal &amp;amp; external access through the service, but I just wanted a quick stop-gap. This challenge convinced me I should re-run with my notebook inside the cluster.
&lt;/div&gt;
&lt;div class=&quot;footnote&quot; id=&quot;_footnotedef_2&quot;&gt;
&lt;a href=&quot;#_footnoteref_2&quot;&gt;2&lt;/a&gt;. You can use the actor API within the other APIs, but it is not part of the same building blocks.
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">After getting the cluster set up in the previous post, it was time to finally play with Dask on the cluster. Thankfully, there are dask-kubernetes and dask-docker projects that provide the framework to do this. Since I&amp;#8217;m still new to Dask, I decided to start off by using Dask from a local notebook (in retrospect maybe not the best choice).</summary></entry><entry><title type="html">Setting up K3s (lightweight Kubernetes) with Persistent Volumes and Minio on ARM</title><link href="https://scalingpythonml.com/2020/10/18/setting-up-k3s-with-pvs-and-minio-on-arm.html" rel="alternate" type="text/html" title="Setting up K3s (lightweight Kubernetes) with Persistent Volumes and Minio on ARM" /><published>2020-10-18T00:00:00-07:00</published><updated>2020-10-18T00:00:00-07:00</updated><id>https://scalingpythonml.com/2020/10/18/setting-up-k3s-with-pvs-and-minio-on-arm</id><content type="html" xml:base="https://scalingpythonml.com/2020/10/18/setting-up-k3s-with-pvs-and-minio-on-arm.html">&lt;p&gt;After the &lt;a href=&quot;http://scalingpythonml.com/2020/09/20/building-the-physical-cluster.html&quot;&gt;last adventure&lt;/a&gt; of getting the rack built and acquiring the machines, it was time to set up the software. Originally, I had planned to do this in a day or two, but in practice, it ran like so many other simple projects and some things I had assumed would be super quick ended up taking much longer than planned.&lt;/p&gt;

&lt;p&gt;Software-wise, I ended up deciding on using &lt;a href=&quot;https://k3s.io/&quot;&gt;K3s&lt;/a&gt; for the Kubernetes deployment, and &lt;a href=&quot;https://rook.io/&quot;&gt;Rook&lt;/a&gt; with Ceph for the persistent volumes. And while I dont travel nearly as much as I used to, I also set up &lt;a href=&quot;https://tailscale.com/&quot;&gt;tailscale for VPN access&lt;/a&gt; from the exciting distant location of my girlfriends house (and incase we ended up having to leave due to air quality).&lt;/p&gt;

&lt;h2 id=&quot;building-the-base-image-for-the-raspberry-pis&quot;&gt;Building the base image for the Raspberry Pis&lt;/h2&gt;

&lt;p&gt;For the Raspberry Pis I decided to use the Ubuntu Raspberry Pi image as its base. The Raspberry Pis boot off of microsd cards, which allows us to pre-build system images rather than running through the install process on each instance. My desktop is an x86, but by following &lt;a href=&quot;https://docs.j7k6.org/raspberry-pi-chroot-armv7-qemu/&quot;&gt;this guide&lt;/a&gt;, I was able to set up an emulation layer so I could cross-build the image for the ARM Raspberry Pis.&lt;/p&gt;

&lt;p&gt;I pre-installed the base layer with Avahi (so the workers and find the leader), ZFS (to create a local storage layer to back our volumes), and necessary container tools. This step ended up taking a while, but I made the most of it by re-using the same image on multiple workers. I also had this stage copy over some configuration files, which didnt depend on having emulation set up.&lt;/p&gt;

&lt;p&gt;However, not everything is easily baked into an image. For example, at first boot, the leader node installs K3s and generates a certificate. Also, when each worker first boots, it connects to the leader and fetches the configuration required to join the cluster. Ubuntu has a mechanism for this (called cloud-init), but rather than figure out a new system I went with the old school self-disabling init-script to do the first boot activities.&lt;/p&gt;

&lt;h2 id=&quot;setting-up-the-jetsons--my-one-x86-machine&quot;&gt;Setting up the Jetsons &amp;amp; my one x86 machine&lt;/h2&gt;

&lt;p&gt;Unlike the Raspberry Pis, the Jetson AGXs &amp;amp; x86 machines have internal storage that they boot from. While the Jetson nano does boot from a microsd card, the images available are installer images that require user interaction to set up. Thankfully, since I wrote everything down in a shell script, it was fairly simple to install the same packages and do the same setup on the Raspberry Pis.&lt;/p&gt;

&lt;p&gt;By default, K3s uses containerd to execute its containers. I found another interesting &lt;a href=&quot;https://www.virtualthoughts.co.uk/2020/03/24/k3s-and-nvidia-jetson-nano/&quot;&gt;blog post on using K3s on Jetsons&lt;/a&gt;, and the main changes that I needed for the setup is to switch from containerd to docker and to configure docker to use the nvidia runtime as the default.&lt;/p&gt;

&lt;h2 id=&quot;getting-the-cluster-to-work&quot;&gt;Getting the cluster to work&lt;/h2&gt;

&lt;p&gt;So, despite pre-baking the images, and having scripts to install everything, I ended up running into a bunch of random problems along the way. These spanned everything from hardware to networking to my software setup.&lt;/p&gt;

&lt;p&gt;The leader node started pretty much as close to perfect as possible, and one of the two workers Raspberry Pis came right up. The second worker Pi kept spitting out malformed packets on the switch  and Im not really sure whats going on with that one  but the case did melt a little bit, which makes me think there might have been a hardware issue with that one node. I did try replacing the network cable and putting it into a different port, but got the same results. When I replaced it with a different Pi everything worked just fine, so Ill debug the broken node when Ive got some spare time.&lt;/p&gt;

&lt;p&gt;I also had some difficulty with my Jetson Nano not booting. At first, I thought maybe the images I was baking were no good, but then I tried the stock image along with a system reset, and that didnt get me any further. Eventually I tried a new microsd card along with the stock image and shorting out pin 40 and it booted like a champ.&lt;/p&gt;

&lt;p&gt;On the networking side, I have a fail-over configured for my home network. However, it seems that despite my thinking I had my router configured to fail-over only if the primary connection has an outage and not do any load-balancing otherwise, I kept getting random connection issues. Once I disabled the fail-over connections the networking issues disappeared. Im not completely sure whats going on with this part, but for now, I can just manually do a failover if sonic goes out.&lt;/p&gt;

&lt;p&gt;On the software side, Avahi worked fine on all of the ARM boards but for some reason doesnt seem to be working on the x86 node The only difference that I could figure was that the x86 node has a static lease configured with the DHCP server, but I dont think that would cause this issue. While having local DNS between the worker nodes would be useful, this was getting near the end of the day, so I just added the leader to the x86s nodes host files and called it a day. The software issues lead us nicely into the self caused issues I had trying to get persistent volumes working.&lt;/p&gt;

&lt;h2 id=&quot;getting-persistent-volumes-working&quot;&gt;Getting persistent volumes working&lt;/h2&gt;

&lt;p&gt;One of the concepts Im interested in playing with is fault tolerance. One potential mechanism for this is using persistent volumes to store some kind of state and recovering from them. In this situation we want our volumes to remain working even if we take a node out of service, so we cant just depend on local volume path provisioning to test this out.&lt;/p&gt;

&lt;p&gt;There are many different projects that could provide persistent volumes on Kubernetes. My first attempt was with GlusterFS; however, the Gluster Kubernetes project has been archived. So after some headaches, I moved on to trying Rook and Ceph. Getting Rook and Ceph running together ended up being quite the learning adventure; both Kris and Duffy jumped on a video call with me to help figure out what was going on. After a lot of debugging  they noticed that it was an architecture issue  namely, many of the CSI containers were not yet cross-compiled for ARM. We did a lot of sleuthing and found unofficial multi-arch versions of these containers. Since then, the &lt;a href=&quot;https://github.com/raspbernetes/multi-arch-images&quot;&gt;rasbernetes&lt;/a&gt; project has started cross-compiling the CSI containers, Ive switched to using as its a bit simpler to keep track of.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/rook-ceph-works.jpeg&quot; alt=&quot;Image of rook/ceph status reporting ok&quot; /&gt;&lt;/p&gt;

&lt;!-- From setup_rook.sh --&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;pushd&lt;/span&gt; /rook/cluster/examples/kubernetes/ceph
kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; common.yaml
kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; rook_operator_arm64.yaml
kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; rook_cluster.yaml
kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; ./csi/rbd/storageclass.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;adding-an-object-store&quot;&gt;Adding an object store&lt;/h2&gt;

&lt;p&gt;During my first run of &lt;a href=&quot;https://www.youtube.com/watch?v=V1SkEl1r4Pg&amp;amp;t=6s&quot;&gt;Apache Spark on the new cluster&lt;/a&gt;, I was reminded of the usefulness of an object-store. Im used to working in an environment where I have an object store available. Thankfully MinIO is available to provide an S3 compatible object store on Kube. It can be backed by the persistent volumes I set up using Rook &amp;amp; Ceph. It can also use local storage, but I decided to use it as a first test of the persistent volumes. Once I had fixed the issues with Ceph, MinIO deployed relatively simply &lt;a href=&quot;https://github.com/minio/charts&quot;&gt;using a helm chart&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While MinIO does build docker containers for arm64 and amd64, it gives them seperate tags. Since Ive got a mix of x86 machines and arm machines in the same cluster I ended up using an un-official multi-arch build. I did end up pinning it to the x86 machine for now, since I havent had the time to recompile the kernels on the arm machines to support rbd.&lt;/p&gt;

&lt;!-- From setup_minio.sh --&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Install minio using ceph to back our storage. Deploy on the x86 because we don't have the rbd kernel module on the ARM nodes. Also we want to save the arm nodes for compute.&lt;/span&gt;
helm &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; minio &lt;span class=&quot;nt&quot;&gt;--generate-name&lt;/span&gt; minio/minio &lt;span class=&quot;nt&quot;&gt;--set&lt;/span&gt;   persistence.storageClass&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;rook-ceph-block,nodeSelector.&lt;span class=&quot;s2&quot;&gt;&quot;beta&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.kubernetes&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.io/arch&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;amd64
&lt;span class=&quot;c&quot;&gt;# Do a helm ls and find the deployment name name&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;deployment_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;helm &lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; minio | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1 | &lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 1&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ACCESS_KEY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;kubectl get secret &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; minio &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$deployment_name&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{.data.accesskey}&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;base64&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--decode&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;SECRET_KEY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;kubectl get secret &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; minio &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$deployment_name&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{.data.secretkey}&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;base64&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--decode&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Defaults are &quot;YOURACCESSKEY&quot; and &quot;YOURSECRETKEY&quot;&lt;/span&gt;
mc &lt;span class=&quot;nb&quot;&gt;alias set&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;deployment_name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-local&quot;&lt;/span&gt; http://localhost:9000 &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ACCESS_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SECRET_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--api&lt;/span&gt; s3v4
mc &lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;deployment_name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-local&quot;&lt;/span&gt;
mc mb &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;deployment_name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-local&quot;&lt;/span&gt;://dask-test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;getting-kubectl-working-from-my-desktop&quot;&gt;Getting kubectl working from my desktop&lt;/h2&gt;

&lt;p&gt;Once I had K3s set up, I wanted to be able to access it from my desktop without having to SSH to a node in the cluster. The &lt;a href=&quot;https://rancher.com/docs/k3s/latest/en/cluster-access/&quot;&gt;K3s documentation says&lt;/a&gt; to copy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/rancher/k3s/k3s.yaml&lt;/code&gt; from the cluster to your local &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.kube/config&lt;/code&gt; and replace the string localhost with the ip/DNS of the leader. Since I had multiple existing clusters I copied the part under each top-level key to the corresponding key, while changing the default string to k3s when copying so that I could remember the context better. The first time I did this I got the whitespace mixed up which lead to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Error in configuration: context was not found for specified context: k3s&lt;/code&gt;  but after I fixed my YAML everything worked :)&lt;/p&gt;

&lt;h2 id=&quot;setting-up-a-vpn-solution&quot;&gt;Setting up a VPN solution&lt;/h2&gt;

&lt;p&gt;While shelter in place has made accessing my home network remotely less important, I do still occasionally get out of the house while staying within my social bubble. Some of my friends from University/Co-Op are now at a company called tailscale, which does magic with WireGuard to allow even double-natted networks to have VPNs. Since I was doing this part as an afterthought, I didnt have tailscale installed on all of the nodes, so I followed the &lt;a href=&quot;https://tailscale.com/kb/1019/subnets&quot;&gt;instructions to enable subnets &lt;/a&gt;(note: I missed enabling the Enable subnet routes in the admin console the first time) and have my desktop act as a gateway host for the K8s cluster when Im traveling. With tailscale, set up I was able to run kubectl from my laptop at Novas place :)&lt;/p&gt;

&lt;p&gt;Josh Patterson has &lt;a href=&quot;https://medium.com/rapids-ai/rapids-anywhere-with-tailscale-my-mobile-device-has-an-rtx-3090-1ce0c7b443fe?source=rss----2d7ba3077a44---4&quot;&gt;a blog post on using tailscale with RAPIDS&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion--alternatives&quot;&gt;Conclusion &amp;amp; alternatives&lt;/h2&gt;

&lt;p&gt;The setup process was a bit more painful than I expected, but it was mostly due to my own choices. In retrospect, building images and flashing them was relatively slow with the emulation required on my old desktop. It would have been much easier to do a non-distributed volume deployment, like local volumes. but I want to set up PVs that I can experiment with using for fault recovery. Nova pointed out that I could have set up sshfs or NFS and could have gotten PVs working with a lot less effort, but by the time we had that conversation the sunk cost fallacy had me believing just one more quick fix was needed and then it would all magically work. Instead of K3s I could have used kubeadm but that seemed relatively heavyweight. Instead of installing K3s manually the &lt;a href=&quot;https://ma.ttias.be/deploying-highly-available-k3s-k3sup/&quot;&gt;k3sup project&lt;/a&gt; could have simplified some of this work. However, since I have a mix of different types of nodes, I wanted a bit more control.&lt;/p&gt;

&lt;p&gt;Now that the cluster is set up, Im going to test the cluster out some more with Apache Spark, the distributed computing program Im most familiar with. Once weve made sure the basics are working with Spark, Im planning on exploring how to get dask running. You can follow along with my adventures on my &lt;a href=&quot;https://www.youtube.com/user/holdenkarau&quot;&gt;YouTube channel over here&lt;/a&gt;, or &lt;a href=&quot;/mailinglist.html&quot;&gt;subscribe to the mailing list&lt;/a&gt; to keep up to date when I write a new post.&lt;/p&gt;</content><author><name></name></author><summary type="html">After the last adventure of getting the rack built and acquiring the machines, it was time to set up the software. Originally, I had planned to do this in a day or two, but in practice, it ran like so many other simple projects and some things I had assumed would be super quick ended up taking much longer than planned.</summary></entry><entry><title type="html">Building the Test Cluster</title><link href="https://scalingpythonml.com/2020/09/20/building-the-physical-cluster.html" rel="alternate" type="text/html" title="Building the Test Cluster" /><published>2020-09-20T00:00:00-07:00</published><updated>2020-09-20T00:00:00-07:00</updated><id>https://scalingpythonml.com/2020/09/20/building-the-physical-cluster</id><content type="html" xml:base="https://scalingpythonml.com/2020/09/20/building-the-physical-cluster.html">&lt;p&gt;To ensure that the results between tests are as comparable as possible, Im using a consistent hardware setup whenever possible. Rather than use a cloud provider I (with the help of Nova) set up a rack with a few different nodes. Using my own hardware allows me to avoid the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors&quot;&gt;noisy neighbor problem&lt;/a&gt;
with any performance numbers and gives me more control over simulating network partitions. A downside is that the environment is not as easily re-creatable.&lt;/p&gt;

&lt;h2 id=&quot;building-the-rack&quot;&gt;Building the Rack&lt;/h2&gt;

&lt;p&gt;If Im honest, a large part of my wanting to do this project is that ever since I was a small kid, Ive always dreamed of running proper networking gear (expired CCNA club represent). I got a &lt;a href=&quot;https://amzn.to/32OCQEq&quot;&gt;rack&lt;/a&gt; and some shelves. (I also got an avocado tree to put on top and a &lt;a href=&quot;https://www.etsy.com/listing/787021025/kubectl-corgi-kubernetes-sticker?ga_order=most_relevant&amp;amp;ga_search_type=all&amp;amp;ga_view_type=gallery&amp;amp;ga_search_query=kubernetes&amp;amp;ref=sr_gallery-1-2&amp;amp;organic_search_click=1&amp;amp;col=1&quot;&gt;cute kubecuddle sticker&lt;/a&gt; for good luck)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/rack.jpg&quot; alt=&quot;Image of my rack with avocado tree on top&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It turns out that putting together a rack is not nearly as much like LEGO as I had imagined. Some of the shelves I got ended up being very heavy (and some did not fit), but thankfully Nova came to the rescue when things got too heavy for me to move.&lt;/p&gt;

&lt;p&gt;After running the rack for about a day, I got a complaint from my neighbor about how loud the fan was, so I swapped it out for some &lt;a href=&quot;https://amzn.to/32NpeJN&quot;&gt;quieter fans&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-hosts&quot;&gt;The Hosts&lt;/h2&gt;

&lt;p&gt;The hosts themselves are a mixture of machines. I picked up three &lt;a href=&quot;https://www.raspberrypi.org/products/raspberry-pi-4-model-b/&quot;&gt;Rasberry Pi 4Bs&lt;/a&gt;. Im also running a &lt;a href=&quot;https://amzn.to/3kBFG6c&quot;&gt;Jetson Nano&lt;/a&gt; and three &lt;a href=&quot;https://amzn.to/3jzO58O&quot;&gt;Jetson AGX Xaviers&lt;/a&gt; to allow me to experiment with GPU acceleration. To support any x86 only code, I also have a small refurbed x86 present.&lt;/p&gt;

&lt;p&gt;For storage I scrounged up some of the free flash drives Ive gotten from conferences over the years to act as storage. This initial set up was not very fast, so I added some inexpensive on-sale external SSD drives.&lt;/p&gt;

&lt;h2 id=&quot;setting-up-kubernetes&quot;&gt;Setting up Kubernetes&lt;/h2&gt;

&lt;p&gt;Since I want to be able to swap between the different Python scaling tools easily, I chose Kubernetes as the base cluster layer rather than installing directly on the nodes. Since it is easy to deploy, I used K3s as the cluster manager. The biggest pain here was figuring out why the storage provisioning I was trying to use wasnt working, but thankfully Duffy came to the rescue, and we figured it out.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;Whats next?&lt;/h2&gt;

&lt;p&gt;Up next, Ill start exploring how the different tools work in this environment. At the very start, Ill just run through each tools tutorials and simulate some network and node failures to see how resilient they are. Once Ive got a better handle on how each tool works, Im planning on exploring how each of them approaches the problem of scaling pandas operations. Once thats done, we can start to get in a lot deeper and see where each tool shines. If you are interested in following along, check out my &lt;a href=&quot;https://www.youtube.com/user/holdenkarau&quot;&gt;Youtube Channel on open source programming&lt;/a&gt; where I will try and stream the process that goes into each post. You can also &lt;a href=&quot;https://www.introductiontomlwithkubeflow.com/?from=introductiontomlwithkubeflow.com&quot;&gt;subscribe to the mailing list for notifications on this on my books&lt;/a&gt; when I get something working well enough to make a new post :)&lt;/p&gt;

&lt;h3 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;/h3&gt;

&lt;p&gt;This blog does not represent any of my employers, past or present, and does not represent any of the software projects or foundations Im involved with. I am one of the developers of Apache Spark and have &lt;a href=&quot;https://amzn.to/2O6KYYH&quot;&gt;some books published on the topic&lt;/a&gt; that may influence my views, but my views do not represent the project.&lt;/p&gt;

&lt;p&gt;In as much as possible, Ive used a common cluster environment for testing these different tools, although some parts have been easier to test out on Minikube.&lt;/p&gt;</content><author><name></name></author><summary type="html">To ensure that the results between tests are as comparable as possible, Im using a consistent hardware setup whenever possible. Rather than use a cloud provider I (with the help of Nova) set up a rack with a few different nodes. Using my own hardware allows me to avoid the noisy neighbor problem with any performance numbers and gives me more control over simulating network partitions. A downside is that the environment is not as easily re-creatable.</summary></entry><entry><title type="html">A First (Brief) Look at Ray on Kubernetes</title><link href="https://scalingpythonml.com/2020/08/16/poke-at-ray.html" rel="alternate" type="text/html" title="A First (Brief) Look at Ray on Kubernetes" /><published>2020-08-16T00:00:00-07:00</published><updated>2020-08-16T00:00:00-07:00</updated><id>https://scalingpythonml.com/2020/08/16/poke-at-ray</id><content type="html" xml:base="https://scalingpythonml.com/2020/08/16/poke-at-ray.html">&lt;p&gt;After my motorcycle/Vespa crash last year I took some time away from work. While I was out and trying to practice getting my typing speed back up, I decided to play with Ray, which was pretty cool. Ray comes out of the same&lt;sup id=&quot;fnref:lab&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:lab&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; research lab that created the initial work that became the basis of Apache Spark. Like Spark, the primary authors have now started a company (Anyscale) to grow Ray. Unlike Spark, Ray is a Python first library and does not depend on the Java Virtual Machine (JVM)  and as someone whos spent way more time than she would like getting the JVM and Python to play together, Ray and its cohort seem quite promising.&lt;/p&gt;

&lt;p&gt;This blog does not represent any of my employers, past or present, and does not represent any of the software projects or foundations Im involved with. I am one of the developers of Apache Spark &lt;a href=&quot;https://amzn.to/2O6KYYH&quot;&gt;and have some books published on the topic&lt;/a&gt; that may influence my views, but my views do not represent the project.&lt;/p&gt;

&lt;h2 id=&quot;installing-ray&quot;&gt;Installing Ray&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.ray.io/en/latest/installation.html&quot;&gt;Installing Ray&lt;/a&gt; was fairly simple, especially due to its lack of JVM dependencies. The one weird thing I encountered while I was installing Ray is the fact that its developers decided to vendor Apache Arrow. This was disappointing because Im interested in using Arrow to get some of these tools to play together and vendored libraries could make it a bit harder. I filed an issue with the ray-project folks, and they quickly responded that they were working on it and then resolved it, so this is something I want to come back to.&lt;/p&gt;

&lt;h2 id=&quot;running-ray-on-k8s&quot;&gt;Running Ray on K8s&lt;/h2&gt;

&lt;p&gt;Since I had not yet built my dedicated test cluster, I decided to give Ray on Kubernetes a shot. The documentation had some room for improvement and I got lost a few times along the way, but on my second try a few days later using the nightly builds I managed to get it running.&lt;/p&gt;

&lt;h2 id=&quot;fault-tolerance&quot;&gt;Fault Tolerance&lt;/h2&gt;

&lt;p&gt;Fault tolerance is especially important in distributed systems like Spark and Ray since as we add more and more computers the chance of one of them failing, or having the network between them fail increases. Different distributed systems take different approaches to fault tolerance, Map-Reduce achieves its fault tolerance by using distributed persistent storage and Spark uses recompute on failures.&lt;sup id=&quot;fnref:fault_tol&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fault_tol&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;fault-tolerance-limitations&quot;&gt;Fault Tolerance Limitations&lt;/h2&gt;

&lt;p&gt;One of the things that really excites me about Ray is its actor model for state. This is really important for some machine learning algorithms, and in Spark, our limitations around handling state (like model weights) have made streaming machine learning algorithms very challenging. One of the big reasons for the limitations around how state is handled is fault tolerance.&lt;/p&gt;

&lt;p&gt;To simulate a failure I created an actor and then killed the pod that was running the actor. Ray did not seem to have any automatic recovery here, which could be the right answer. In the future, I want to experiment and see if there is a way to pair Ray with a durable distributed database (or another system) to allow the recovery of actors.&lt;/p&gt;

&lt;p&gt;I want to be clear: This is about the same as in Spark. Spark only&lt;sup id=&quot;fnref:spark_state&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:spark_state&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; allows state to accrue on the driver, and recovery of state on the failure of the driver requires some additional custom code.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;Whats next?&lt;/h2&gt;

&lt;p&gt;The ray-project looks really interesting. Along with Dask and other new Python-first tools were entering a new era of options for scaling our Python ML code. Seeing Apache Arrow inside of Ray is reassuring since one of my considerations is how we can make our tools work together, and I think Arrow has the potential to serve as a bridge between the different parts of our ecosystem. Up next Im going to try and set up Dask on my new K8s cluster, and then also re-create this initial experiment on physical hardware instead of Minikube. If youve got thoughts or suggestions for what youd like to see next, please do send me an e-mail and file an issue against the webpage on GitHub.&lt;/p&gt;

&lt;p&gt;You can also follow along with my streams around &lt;a href=&quot;https://www.youtube.com/user/holdenkarau&quot;&gt;distributed computing and open-source on my YouTube channel&lt;/a&gt;. The two videos for this post are &lt;a href=&quot;https://www.youtube.com/watch?v=WBNmF-wyAlE&quot;&gt;Installing &amp;amp; Poking at Ray&lt;/a&gt; and &lt;a href=&quot;https://www.youtube.com/watch?v=IUI5okVvgbQ&quot;&gt;Trying the Ray Project on Kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If your interested in learning more about Ray and dont want to wait for me, there is a &lt;a href=&quot;https://github.com/ray-project/&quot;&gt;great collection of tutorials in the project&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:lab&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Well same-ish. Its technically a bit more complicated because of the way the professors choose to run their labs, but if you look at the advisors youll notice a lot of overlap.&lt;a href=&quot;#fnref:lab&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fault_tol&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Technically its a bit more complicated, and Spark can use a hybrid of these two models. In some internal places (like its ALS implementation and other iterative algorithms), Spark uses distributed persistent storage for fault tolerance.&lt;a href=&quot;#fnref:fault_tol&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:spark_state&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Streaming Spark is a bit different&lt;a href=&quot;#fnref:spark_state&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">After my motorcycle/Vespa crash last year I took some time away from work. While I was out and trying to practice getting my typing speed back up, I decided to play with Ray, which was pretty cool. Ray comes out of the same1 research lab that created the initial work that became the basis of Apache Spark. Like Spark, the primary authors have now started a company (Anyscale) to grow Ray. Unlike Spark, Ray is a Python first library and does not depend on the Java Virtual Machine (JVM)  and as someone whos spent way more time than she would like getting the JVM and Python to play together, Ray and its cohort seem quite promising. Well same-ish. Its technically a bit more complicated because of the way the professors choose to run their labs, but if you look at the advisors youll notice a lot of overlap.&amp;#8617;</summary></entry></feed>